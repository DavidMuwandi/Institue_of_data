{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MV1ykjySSrEu"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "42orCR4NSrEw"
   },
   "source": [
    "# Lab 5.1 \n",
    "# *Logistic Regression*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6dger9XSrEz"
   },
   "source": [
    "## Predicting Survival on the Titanic\n",
    "\n",
    "The Titanic sank during her maiden voyage after colliding with an iceberg (April 15, 1912). Due to a commercial decision there were insufficient lifeboats, a fact that was partially responsible for the loss 1,502 out of 2,224 passengers and crew. \n",
    "\n",
    "The Titanic dataset incorporates many features of typical real-world problems: a mixture of continuous and discrete features, missing data, linear covariance, and an element of random chance. Predicting survival therefore involves many practical data science skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BpW4z29ASrE1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSpp7YdtSrE8"
   },
   "source": [
    "### 1. Load Data\n",
    "\n",
    "Load the `titanic.csv` file into a DataFrame named \"titanic\", with index column = `PassengerId`. Display the head of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXnrsCXeSrE-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "titanic = pd.read_csv(\"titanic.csv\", index_col = 'PassengerId')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BA8iN36rSrFE"
   },
   "source": [
    "Why would we want to set an index column based on `PassengerId`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwYgjo5JSrFG"
   },
   "source": [
    "ANSWER: This column is the key to training and testing our model. We use it to partition the dataset and to test the predictions of our model against known outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8KELa83wYO5Z"
   },
   "source": [
    "<a name=\"datadictionary\"></a>\n",
    "### 2. Data Dictionary \n",
    "\n",
    "If a data dictionary is available, it is handy to include it in the notebook for reference:\n",
    "\n",
    "| Variable |                                 Definition | Key                                            |\n",
    "|----------|-------------------------------------------:|------------------------------------------------|\n",
    "| Survival | Survival                                   | 0 = No, 1 = Yes                                |\n",
    "| Pclass   | Ticket class                               | 1 = 1st, 2 = 2nd, 3 = 3rd                      |\n",
    "| Sex      | Sex                                        |                                                |\n",
    "| Age      | Age in years                               |                                                |\n",
    "| SibSp    | # of siblings / spouses aboard the Titanic |                                                |\n",
    "| Parch    | # of parents / children aboard the Titanic |                                                |\n",
    "| Ticket   | Ticket number                              |                                                |\n",
    "| Fare     | Passenger fare                             |                                                |\n",
    "| Cabin    | Cabin number                               |                                                |\n",
    "| Embarked | Port of Embarkation                        | C = Cherbourg, Q = Queenstown, S = Southampton |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-CM_PnS0YO5a"
   },
   "source": [
    "### 2. EDA\n",
    "\n",
    "Explore dataset. Find features to predict `Survived`. Get rid of null values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-nj-5WrYO5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket',\n",
       "       'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      int64\n",
       "Pclass        int64\n",
       "Name         object\n",
       "Sex          object\n",
       "Age         float64\n",
       "SibSp         int64\n",
       "Parch         int64\n",
       "Ticket       object\n",
       "Fare        float64\n",
       "Cabin        object\n",
       "Embarked     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing Age with overall mean\n",
    "\n",
    "titanic.Age.fillna(titanic.Age.mean(), inplace = True, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic.Age.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age           0\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uxrHcNYzSrFN"
   },
   "source": [
    "### 3. Numerical Predictors Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWs3gb8KSrFP"
   },
   "source": [
    "#### 3.1. Set Target and Features\n",
    "\n",
    "To begin, let's try a model based on the passenger class (`Pclass`) and parents/children features (`Parch`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hIpl6VeSrFR"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "#Predictors\n",
    "X = titanic[['Pclass', 'Parch']]\n",
    "\n",
    "#target\n",
    "Y = titanic['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ILBoBYUYO5g"
   },
   "source": [
    "#### 3.2 Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kc2wfIDqSrFT"
   },
   "source": [
    "Partition the data into training and testing subsets:\n",
    "\n",
    "- Use `random_state` = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbfZLOdRSrFU"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2 ,random_state = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 2), (712,), (179, 2), (179,))"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8p1bdc1SrFW"
   },
   "source": [
    "#### 3.3. Build Model\n",
    "\n",
    "Prepare a model by creating an instance of the `LogisticRegression` class from the `sklearn.linear_model` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIhxqfrXSrFY"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Create Model\n",
    "\n",
    "model1 = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HJNFicg9SrFa"
   },
   "source": [
    "Now train it on the training data subset, using the `fit` method of the model object (Nb. by default, `fit` will print the hyperparameters of the model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lzefYEzfSrFb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "# Fit Model\n",
    "\n",
    "\n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JsfC92SgSrFd"
   },
   "source": [
    "The computed coefficients are an array (`coef_`) stored in the 1st element of an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kr7GMdllSrFe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90824213,  0.33432156]])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "\n",
    "model1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KL7uKC8USrFh"
   },
   "source": [
    "The computed intercept (`intercept_`) is the 1st element of another array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4TudzIpjSrFi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.40820621])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "model1.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSc0PEbjSrFk"
   },
   "source": [
    "We can create tuples of the predictor names and coefficients like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlaUpqxRSrFk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Parch', 0.334321555147779), ('Pclass', -0.908242134146983)}\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "feature_cols = ['Pclass', 'Parch']\n",
    "\n",
    "print(set(zip(feature_cols, model1.coef_[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "duCXO8aqSrFm"
   },
   "source": [
    "If we want formatted output, here is a neat way to list the coefficients by predictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jiz-vjACSrFm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass      -0.908242\n",
      "Parch       +0.334322\n"
     ]
    }
   ],
   "source": [
    "for col in zip(X_train.columns, model1.coef_[0]):\n",
    "    print('{:<10s}  {:+.06f}'.format(col[0], col[1]))  # Nb. increase 10 for longer names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65YucOmmSrFo"
   },
   "source": [
    "This result implies that survival declines with passenger class (i.e. 1st class is highest) but increases with the number of parents or children in a group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5FkRLS3oSrFp"
   },
   "source": [
    "Let's see how well the model fit the training data. The `accuracy_score` is the proportion of correct predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Gep5OXUSrFp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6924157303370787"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "\n",
    "model1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_alclvzjSrFs"
   },
   "source": [
    "What is the  `accuracy_score` for the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2GRLpAdmSrFt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6536312849162011"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "\n",
    "y_test_pred = model1.predict(X_test)\n",
    "y_test_pred\n",
    "\n",
    "model1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KwgPpa5sSrFw"
   },
   "source": [
    "What can we say aout this result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7XUWZoBRSrFx"
   },
   "source": [
    "ANSWER\n",
    "- ...\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBWjeIE2YO6D"
   },
   "source": [
    "#### 3.4. Add `AGE` as Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rxmg3b2wSrFy"
   },
   "source": [
    "Let's include `Age` in the model. As we know from our EDA, this feature has many missing values. We don't want to throw away so many rows, so we will replace `NA` values with imputed values (e.g. the overall mean age):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IVfjTrF8SrFy"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# age imputing done in EDA\n",
    "X = titanic[['Pclass', 'Parch', 'Age']]\n",
    "Y = titanic.Survived\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2 ,random_state = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVSXN-tfYO6J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7247191011235955"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model\n",
    "\n",
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit Model\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Score\n",
    "\n",
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6_aYK1oSrF0"
   },
   "source": [
    "So, including age did little to reduce the variance in our model. Why might this be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w1pzei3QSrF1"
   },
   "source": [
    "ANSWER\n",
    "\n",
    "- Age predictor has little to no effect on Survival\n",
    "_ Age predictor \n",
    "- ...\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bPLvK9s2SrF1"
   },
   "source": [
    "Let's see where the model is going wrong by showing the Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class = logreg.predict(X_test)\n",
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rAzihOU2SrF1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87 19]\n",
      " [43 30]]\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S-mclQOiSrF3"
   },
   "source": [
    "Nb. Here is how `confusion_matrix` arranges its output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QquT0zbNSrF4",
    "outputId": "bc777d64-736a-4bc3-bcef-8edaa99caafe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['TN' 'FP']\n",
      " ['FN' 'TP']]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray([['TN', 'FP'], ['FN', 'TP']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9sT-8GqSrF6"
   },
   "source": [
    "Which type of error is more prevalent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E08zup6gSrF7"
   },
   "source": [
    "ANSWER: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOPBQRsGSrF8"
   },
   "source": [
    "Maybe we aren't using the right cut-off value. By default, we are predicting that `Survival` = True if the probability >= 0.5, but we could use a different threshold. The ROC curve helps us decide (as well as showing us how good our predictive model really is):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqqqTVZCSrF9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the prediction values for each of the test observations using predict_proba() function rather than just predict\n",
    "preds = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Store the false positive rate(fpr), true positive rate (tpr) in vectors for use in the graph\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, preds)\n",
    "\n",
    "# Store the Area Under the Curve (AUC) so we can annotate our graph with theis metric\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC Curve\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw = lw, label = 'ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color = 'navy', lw = lw, linestyle = '--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WpOA8_TFSrF_"
   },
   "source": [
    "### 4. Including Categorical Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zp8r1ePeSrF_"
   },
   "source": [
    "So far, we've only used numerical features for prediction. Let's convert the character features to dummy variables so we can include them in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cbwHVP-bSrGA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived                                               Name  \\\n",
       "PassengerId                                                                \n",
       "1                   0                            Braund, Mr. Owen Harris   \n",
       "2                   1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "3                   1                             Heikkinen, Miss. Laina   \n",
       "4                   1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "5                   0                           Allen, Mr. William Henry   \n",
       "\n",
       "              Age  SibSp  Parch            Ticket     Fare Cabin  Sex_female  \\\n",
       "PassengerId                                                                    \n",
       "1            22.0      1      0         A/5 21171   7.2500   NaN           0   \n",
       "2            38.0      1      0          PC 17599  71.2833   C85           1   \n",
       "3            26.0      0      0  STON/O2. 3101282   7.9250   NaN           1   \n",
       "4            35.0      1      0            113803  53.1000  C123           1   \n",
       "5            35.0      0      0            373450   8.0500   NaN           0   \n",
       "\n",
       "             Sex_male  Embarked_C  Embarked_Q  Embarked_S  Pclass_1  Pclass_2  \\\n",
       "PassengerId                                                                     \n",
       "1                   1           0           0           1         0         0   \n",
       "2                   0           1           0           0         1         0   \n",
       "3                   0           0           0           1         0         0   \n",
       "4                   0           0           0           1         1         0   \n",
       "5                   1           0           0           1         0         0   \n",
       "\n",
       "             Pclass_3  \n",
       "PassengerId            \n",
       "1                   1  \n",
       "2                   0  \n",
       "3                   1  \n",
       "4                   0  \n",
       "5                   1  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_with_dummies = pd.get_dummies(data = titanic, columns = ['Sex', 'Embarked', 'Pclass'], \n",
    "                                      prefix = ['Sex', 'Embarked', 'Pclass'] )\n",
    "titanic_with_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_WnnEWdSrGB"
   },
   "source": [
    "So, this created a column for every possible value of every categorical variable. (A more compact approach would have been to reduce the number of dummy variables by one for each feature, so that the first vriable from each captures two possible states.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWjijSClSrGB"
   },
   "source": [
    "Now that we have data on sex, embarkation port, and passenger class we can try to improve our `Age` imputation by stratifying it by the means of groups within the passenger population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYTqaSTySrGC"
   },
   "outputs": [],
   "source": [
    "titanic_with_dummies['Age'] = titanic_with_dummies[[\"Age\", \"Parch\", \"Sex_male\", \"Pclass_1\", \"Pclass_2\"]].groupby([\"Parch\", \"Sex_male\", \"Pclass_1\", \"Pclass_2\"])[\"Age\"].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMt6G9JYSrGE"
   },
   "source": [
    "Now train the model using the expanded set of predictors and compute the accuracy score for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dSX26hn-SrGE"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[29.69911765 30.         34.         21.         62.         29.\n 18.         29.69911765 18.         29.69911765 44.         29.69911765\n 45.         29.69911765 15.          9.         38.         29.69911765\n 19.         24.5        71.         17.         53.         29.69911765\n 23.         37.         24.         51.         25.         29.69911765\n 37.         32.          4.         28.5        11.         32.\n 35.         29.69911765 17.         33.         56.         29.69911765\n 29.69911765 52.         42.         29.69911765 49.         19.\n 19.         27.         38.          2.         12.          0.42\n 34.         38.         29.69911765 29.69911765 29.69911765 17.\n 22.         60.         23.         30.         32.         44.\n 31.         29.         34.         48.         33.         41.\n 29.         36.         11.         58.         18.         44.\n 40.         31.          9.         13.         29.69911765 29.69911765\n 24.         27.         33.         25.         46.         17.\n 28.         29.69911765 20.         29.69911765 47.         36.\n 16.          5.         25.         39.         18.         40.\n 24.         18.         19.         17.         30.         24.\n 29.69911765 24.         39.          2.         21.         43.\n 18.         29.69911765 54.         14.         29.69911765 32.\n 29.69911765 23.         37.          1.         22.         33.\n 43.          4.         29.69911765 24.          1.         29.69911765\n 29.69911765 58.         29.69911765 28.          9.         50.\n 21.         31.         28.         26.         21.         14.\n 21.         32.         19.          0.92       29.69911765 29.69911765\n  8.          2.         33.          9.         23.         70.5\n 36.         29.69911765 39.         29.69911765 29.69911765 32.\n 17.         22.         45.         18.         20.          4.\n 20.         30.         21.         40.         17.         29.69911765\n 65.         60.          0.83       29.69911765 27.         27.\n 20.         20.         29.69911765 21.         29.69911765 44.\n  9.         29.69911765 22.         20.5        25.         24.\n 50.         22.         14.         35.         62.         42.\n 36.         19.         29.69911765 18.         29.         24.\n 70.         29.69911765 42.         18.         49.         29.\n  3.         34.         32.5         0.67       21.         18.\n 29.69911765 36.         29.69911765 29.         29.69911765 26.\n 19.         54.         14.         35.         66.         29.69911765\n 28.         35.         29.69911765 65.          4.         34.\n 31.         40.         44.         16.         29.69911765 36.\n 29.69911765 33.         29.69911765 32.         29.69911765 26.\n 28.         29.69911765 29.69911765 15.         60.         16.\n 20.         29.69911765 29.69911765 22.         50.         33.\n  3.         29.69911765 63.         16.         40.5        31.\n 29.69911765 29.69911765 28.         24.         74.         22.\n 44.          0.83       26.         39.         21.         56.\n 29.69911765 29.69911765 29.         36.         17.         29.69911765\n 29.69911765 50.         32.         29.69911765 25.         24.\n 50.         19.         16.         47.         27.         50.\n 42.         29.69911765 25.         40.         40.         41.\n  4.         22.         30.         32.         41.         17.\n 24.         30.5        29.69911765 27.         70.         21.\n 49.         29.69911765 16.         19.         21.         30.\n 29.69911765 23.         29.         29.69911765 20.         35.\n 50.         29.69911765 47.         36.         19.         19.\n 10.         45.5        25.         24.         38.         29.69911765\n 30.          8.         39.         59.         25.         34.\n 43.         47.         29.69911765 19.         42.         40.\n 29.69911765 51.         22.         31.         29.69911765 36.\n  9.         46.         31.         25.         36.         26.\n 30.         41.         29.69911765 29.69911765 21.         29.69911765\n 28.         22.         29.69911765 28.         45.         30.\n 20.         29.69911765 26.         54.         28.         39.\n 51.         33.          1.         13.          6.         28.5\n 28.         45.         29.69911765 32.         35.         29.69911765\n 29.69911765 39.         24.         30.         38.         54.\n 22.         30.         29.69911765  4.         18.         31.\n 48.         24.         28.         26.         22.         29.69911765\n 18.         64.         18.         51.         32.         48.\n 29.69911765 29.69911765 19.         50.         16.         33.\n 23.         16.         45.         20.         42.         56.\n 29.69911765 29.69911765  3.         51.         32.5        16.\n 21.         63.         29.69911765 28.         29.69911765  9.\n 26.         29.69911765 18.         29.69911765 35.         61.\n 50.         38.         17.         45.         19.         32.\n 17.         40.         29.69911765 48.         30.         19.\n 30.         27.         39.         30.         29.69911765 19.\n 28.         26.         29.69911765 29.69911765 29.         21.\n 21.         26.         29.         24.         29.69911765 25.\n 19.         20.          8.         35.         27.         28.\n 52.         31.         29.69911765 30.         29.69911765 29.69911765\n 29.69911765 19.         29.69911765 51.         29.69911765 22.\n 29.69911765  4.         25.         27.         29.69911765 18.\n 33.          2.         64.         29.         29.69911765  4.\n 29.69911765 29.69911765 21.         30.         29.69911765  4.\n 24.         29.69911765 29.69911765 47.         18.         25.\n 29.69911765  8.         15.         30.         29.69911765 23.5\n 34.         29.69911765 36.         24.         36.         37.\n 45.         44.         19.         26.         22.         41.\n 39.         27.         18.         34.         29.         34.\n 29.69911765 54.          1.         20.         29.69911765 25.\n 40.         57.         29.69911765  7.         80.         35.\n 61.         26.         29.69911765 19.         29.69911765 36.\n 45.         29.69911765 29.69911765 25.         60.         16.\n 24.         29.69911765 55.         33.         45.         34.\n  9.         36.         30.          3.         29.69911765 34.\n 50.         34.         52.         55.5        31.          4.\n 35.         71.         24.         56.         33.         32.\n 33.         34.5        17.         18.         38.         25.\n 48.         29.69911765 40.         27.         42.         23.\n 24.         20.          0.75       29.69911765 54.         34.\n 30.         48.         24.         27.         52.         22.\n 29.69911765 19.         32.         47.          3.         22.\n 29.69911765 29.69911765  6.         24.         35.         29.69911765\n 30.         42.         29.69911765 29.69911765 36.         32.\n 51.         22.          1.         35.         29.69911765 42.\n  5.         15.         34.         32.         16.         38.\n 29.69911765 29.69911765 38.         29.69911765 29.69911765 55.\n 29.69911765  2.         42.         29.         52.         29.69911765\n 22.          3.         29.69911765 29.69911765 47.         44.\n 40.         29.69911765 36.         16.         11.         65.\n 29.69911765 29.69911765 21.         29.69911765 25.         29.69911765\n 40.         24.         54.         28.         30.         62.\n 40.          2.         23.         22.         16.         22.\n 37.         23.         31.         25.         28.         23.\n 43.         29.69911765 62.         29.69911765 38.         41.\n 45.         30.         28.         36.         28.         31.\n 36.         45.         18.         35.         48.         19.\n 30.5        21.         29.69911765 21.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-299-2ff133588785>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mreglog_expanded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mreglog_expanded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1340\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[0;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    617\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    620\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[29.69911765 30.         34.         21.         62.         29.\n 18.         29.69911765 18.         29.69911765 44.         29.69911765\n 45.         29.69911765 15.          9.         38.         29.69911765\n 19.         24.5        71.         17.         53.         29.69911765\n 23.         37.         24.         51.         25.         29.69911765\n 37.         32.          4.         28.5        11.         32.\n 35.         29.69911765 17.         33.         56.         29.69911765\n 29.69911765 52.         42.         29.69911765 49.         19.\n 19.         27.         38.          2.         12.          0.42\n 34.         38.         29.69911765 29.69911765 29.69911765 17.\n 22.         60.         23.         30.         32.         44.\n 31.         29.         34.         48.         33.         41.\n 29.         36.         11.         58.         18.         44.\n 40.         31.          9.         13.         29.69911765 29.69911765\n 24.         27.         33.         25.         46.         17.\n 28.         29.69911765 20.         29.69911765 47.         36.\n 16.          5.         25.         39.         18.         40.\n 24.         18.         19.         17.         30.         24.\n 29.69911765 24.         39.          2.         21.         43.\n 18.         29.69911765 54.         14.         29.69911765 32.\n 29.69911765 23.         37.          1.         22.         33.\n 43.          4.         29.69911765 24.          1.         29.69911765\n 29.69911765 58.         29.69911765 28.          9.         50.\n 21.         31.         28.         26.         21.         14.\n 21.         32.         19.          0.92       29.69911765 29.69911765\n  8.          2.         33.          9.         23.         70.5\n 36.         29.69911765 39.         29.69911765 29.69911765 32.\n 17.         22.         45.         18.         20.          4.\n 20.         30.         21.         40.         17.         29.69911765\n 65.         60.          0.83       29.69911765 27.         27.\n 20.         20.         29.69911765 21.         29.69911765 44.\n  9.         29.69911765 22.         20.5        25.         24.\n 50.         22.         14.         35.         62.         42.\n 36.         19.         29.69911765 18.         29.         24.\n 70.         29.69911765 42.         18.         49.         29.\n  3.         34.         32.5         0.67       21.         18.\n 29.69911765 36.         29.69911765 29.         29.69911765 26.\n 19.         54.         14.         35.         66.         29.69911765\n 28.         35.         29.69911765 65.          4.         34.\n 31.         40.         44.         16.         29.69911765 36.\n 29.69911765 33.         29.69911765 32.         29.69911765 26.\n 28.         29.69911765 29.69911765 15.         60.         16.\n 20.         29.69911765 29.69911765 22.         50.         33.\n  3.         29.69911765 63.         16.         40.5        31.\n 29.69911765 29.69911765 28.         24.         74.         22.\n 44.          0.83       26.         39.         21.         56.\n 29.69911765 29.69911765 29.         36.         17.         29.69911765\n 29.69911765 50.         32.         29.69911765 25.         24.\n 50.         19.         16.         47.         27.         50.\n 42.         29.69911765 25.         40.         40.         41.\n  4.         22.         30.         32.         41.         17.\n 24.         30.5        29.69911765 27.         70.         21.\n 49.         29.69911765 16.         19.         21.         30.\n 29.69911765 23.         29.         29.69911765 20.         35.\n 50.         29.69911765 47.         36.         19.         19.\n 10.         45.5        25.         24.         38.         29.69911765\n 30.          8.         39.         59.         25.         34.\n 43.         47.         29.69911765 19.         42.         40.\n 29.69911765 51.         22.         31.         29.69911765 36.\n  9.         46.         31.         25.         36.         26.\n 30.         41.         29.69911765 29.69911765 21.         29.69911765\n 28.         22.         29.69911765 28.         45.         30.\n 20.         29.69911765 26.         54.         28.         39.\n 51.         33.          1.         13.          6.         28.5\n 28.         45.         29.69911765 32.         35.         29.69911765\n 29.69911765 39.         24.         30.         38.         54.\n 22.         30.         29.69911765  4.         18.         31.\n 48.         24.         28.         26.         22.         29.69911765\n 18.         64.         18.         51.         32.         48.\n 29.69911765 29.69911765 19.         50.         16.         33.\n 23.         16.         45.         20.         42.         56.\n 29.69911765 29.69911765  3.         51.         32.5        16.\n 21.         63.         29.69911765 28.         29.69911765  9.\n 26.         29.69911765 18.         29.69911765 35.         61.\n 50.         38.         17.         45.         19.         32.\n 17.         40.         29.69911765 48.         30.         19.\n 30.         27.         39.         30.         29.69911765 19.\n 28.         26.         29.69911765 29.69911765 29.         21.\n 21.         26.         29.         24.         29.69911765 25.\n 19.         20.          8.         35.         27.         28.\n 52.         31.         29.69911765 30.         29.69911765 29.69911765\n 29.69911765 19.         29.69911765 51.         29.69911765 22.\n 29.69911765  4.         25.         27.         29.69911765 18.\n 33.          2.         64.         29.         29.69911765  4.\n 29.69911765 29.69911765 21.         30.         29.69911765  4.\n 24.         29.69911765 29.69911765 47.         18.         25.\n 29.69911765  8.         15.         30.         29.69911765 23.5\n 34.         29.69911765 36.         24.         36.         37.\n 45.         44.         19.         26.         22.         41.\n 39.         27.         18.         34.         29.         34.\n 29.69911765 54.          1.         20.         29.69911765 25.\n 40.         57.         29.69911765  7.         80.         35.\n 61.         26.         29.69911765 19.         29.69911765 36.\n 45.         29.69911765 29.69911765 25.         60.         16.\n 24.         29.69911765 55.         33.         45.         34.\n  9.         36.         30.          3.         29.69911765 34.\n 50.         34.         52.         55.5        31.          4.\n 35.         71.         24.         56.         33.         32.\n 33.         34.5        17.         18.         38.         25.\n 48.         29.69911765 40.         27.         42.         23.\n 24.         20.          0.75       29.69911765 54.         34.\n 30.         48.         24.         27.         52.         22.\n 29.69911765 19.         32.         47.          3.         22.\n 29.69911765 29.69911765  6.         24.         35.         29.69911765\n 30.         42.         29.69911765 29.69911765 36.         32.\n 51.         22.          1.         35.         29.69911765 42.\n  5.         15.         34.         32.         16.         38.\n 29.69911765 29.69911765 38.         29.69911765 29.69911765 55.\n 29.69911765  2.         42.         29.         52.         29.69911765\n 22.          3.         29.69911765 29.69911765 47.         44.\n 40.         29.69911765 36.         16.         11.         65.\n 29.69911765 29.69911765 21.         29.69911765 25.         29.69911765\n 40.         24.         54.         28.         30.         62.\n 40.          2.         23.         22.         16.         22.\n 37.         23.         31.         25.         28.         23.\n 43.         29.69911765 62.         29.69911765 38.         41.\n 45.         30.         28.         36.         28.         31.\n 36.         45.         18.         35.         48.         19.\n 30.5        21.         29.69911765 21.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "# Set Feature Both Numerical, Categorical\n",
    "\n",
    "X = [titanic_with_dummies['Age'], \n",
    "Y = titanic_with_dummies.Survived\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2 ,random_state = 1 )\n",
    "\n",
    "reglog_expanded = LogisticRegression()\n",
    "\n",
    "reglog_expanded.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "1      22.000000\n",
       "2      38.000000\n",
       "3      26.000000\n",
       "4      35.000000\n",
       "5      35.000000\n",
       "         ...    \n",
       "887    27.000000\n",
       "888    19.000000\n",
       "889    29.699118\n",
       "890    26.000000\n",
       "891    32.000000\n",
       "Name: Age, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CLTPHMa2SrGF"
   },
   "source": [
    "Plot the ROC curve for the new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqkichKQYO6l"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlT5P8TfSrGH"
   },
   "source": [
    "Can we improve the model by including the remaining features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qpqcaw8NYO6p"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NHrtlx8tSrGP"
   },
   "source": [
    "## Homework\n",
    "\n",
    "1. Remove the `random_state` parameter (if you have used), so that the data partition will be different every time, and run through the final modelling process a few times. Do the results change?\n",
    "\n",
    "2. Use cross-validation to assess the quality of the model when overfitting is controlled. Does the accuracy improve?\n",
    "\n",
    "3. Look at the `fpr` & `tpr` vectors for the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2021 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "WpOA8_TFSrF_"
   ],
   "name": "DSIA_Lab_5_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
