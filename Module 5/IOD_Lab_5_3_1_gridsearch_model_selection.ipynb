{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XebDJ3UnS3n3"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_-HjrL6S3n5"
   },
   "source": [
    "# Lab 5.3.1 \n",
    "# *Support Vector Machines*\n",
    "\n",
    "SVMs use linear algebra to find an (n-1)-dimensional boundary that separates classes within an n-dimensional space. In practical terms, this technique provides a conceptually simple way to predict class membership from a set of features. \n",
    "\n",
    "The standard (linear) SVM is immediately applicable to linear classification problems. Furthermore, by applying transformations to the feature space it is possible to tackle nonlinear classificaiton problems. These transforms are called *kernels*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azVVNUxHYKej"
   },
   "source": [
    "### 1. Load Data\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1) ID number 2) Diagnosis (M = malignant, B = benign) 3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter) b) texture (standard deviation of gray-scale values) c) perimeter d) area e) smoothness (local variation in radius lengths) f) compactness (perimeter^2 / area - 1.0) g) concavity (severity of concave portions of the contour) h) concave points (number of concave portions of the contour) i) symmetry j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "All feature values are recoded with four significant digits.\n",
    "\n",
    "Missing attribute values: none\n",
    "\n",
    "Class distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:13:16.458182Z",
     "start_time": "2019-05-09T05:13:16.454244Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "aICmn_7xYKek"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/dmuwa/OneDrive/Documents/1.IoD/Data_Set/data/data/breast-cancer-wisconsin-data.csv\", index_col = \"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FPRqG96QYKen"
   },
   "source": [
    "### 2. EDA \n",
    "\n",
    "- Explore dataset. Clean data (if required)\n",
    "- Find features to predict class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926424</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926682</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926954</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927241</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92751</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                         \n",
       "842302           M        17.99         10.38          122.80     1001.0   \n",
       "842517           M        20.57         17.77          132.90     1326.0   \n",
       "84300903         M        19.69         21.25          130.00     1203.0   \n",
       "84348301         M        11.42         20.38           77.58      386.1   \n",
       "84358402         M        20.29         14.34          135.10     1297.0   \n",
       "...            ...          ...           ...             ...        ...   \n",
       "926424           M        21.56         22.39          142.00     1479.0   \n",
       "926682           M        20.13         28.25          131.20     1261.0   \n",
       "926954           M        16.60         28.08          108.30      858.1   \n",
       "927241           M        20.60         29.33          140.10     1265.0   \n",
       "92751            B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "          smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                            \n",
       "842302            0.11840           0.27760         0.30010   \n",
       "842517            0.08474           0.07864         0.08690   \n",
       "84300903          0.10960           0.15990         0.19740   \n",
       "84348301          0.14250           0.28390         0.24140   \n",
       "84358402          0.10030           0.13280         0.19800   \n",
       "...                   ...               ...             ...   \n",
       "926424            0.11100           0.11590         0.24390   \n",
       "926682            0.09780           0.10340         0.14400   \n",
       "926954            0.08455           0.10230         0.09251   \n",
       "927241            0.11780           0.27700         0.35140   \n",
       "92751             0.05263           0.04362         0.00000   \n",
       "\n",
       "          concave points_mean  symmetry_mean  ...  texture_worst  \\\n",
       "id                                            ...                  \n",
       "842302                0.14710         0.2419  ...          17.33   \n",
       "842517                0.07017         0.1812  ...          23.41   \n",
       "84300903              0.12790         0.2069  ...          25.53   \n",
       "84348301              0.10520         0.2597  ...          26.50   \n",
       "84358402              0.10430         0.1809  ...          16.67   \n",
       "...                       ...            ...  ...            ...   \n",
       "926424                0.13890         0.1726  ...          26.40   \n",
       "926682                0.09791         0.1752  ...          38.25   \n",
       "926954                0.05302         0.1590  ...          34.12   \n",
       "927241                0.15200         0.2397  ...          39.42   \n",
       "92751                 0.00000         0.1587  ...          30.37   \n",
       "\n",
       "          perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "id                                                                           \n",
       "842302             184.60      2019.0           0.16220            0.66560   \n",
       "842517             158.80      1956.0           0.12380            0.18660   \n",
       "84300903           152.50      1709.0           0.14440            0.42450   \n",
       "84348301            98.87       567.7           0.20980            0.86630   \n",
       "84358402           152.20      1575.0           0.13740            0.20500   \n",
       "...                   ...         ...               ...                ...   \n",
       "926424             166.10      2027.0           0.14100            0.21130   \n",
       "926682             155.00      1731.0           0.11660            0.19220   \n",
       "926954             126.70      1124.0           0.11390            0.30940   \n",
       "927241             184.60      1821.0           0.16500            0.86810   \n",
       "92751               59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "          concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "id                                                                \n",
       "842302             0.7119                0.2654          0.4601   \n",
       "842517             0.2416                0.1860          0.2750   \n",
       "84300903           0.4504                0.2430          0.3613   \n",
       "84348301           0.6869                0.2575          0.6638   \n",
       "84358402           0.4000                0.1625          0.2364   \n",
       "...                   ...                   ...             ...   \n",
       "926424             0.4107                0.2216          0.2060   \n",
       "926682             0.3215                0.1628          0.2572   \n",
       "926954             0.3403                0.1418          0.2218   \n",
       "927241             0.9387                0.2650          0.4087   \n",
       "92751              0.0000                0.0000          0.2871   \n",
       "\n",
       "          fractal_dimension_worst  Unnamed: 32  \n",
       "id                                              \n",
       "842302                    0.11890          NaN  \n",
       "842517                    0.08902          NaN  \n",
       "84300903                  0.08758          NaN  \n",
       "84348301                  0.17300          NaN  \n",
       "84358402                  0.07678          NaN  \n",
       "...                           ...          ...  \n",
       "926424                    0.07115          NaN  \n",
       "926682                    0.06637          NaN  \n",
       "926954                    0.07820          NaN  \n",
       "927241                    0.12400          NaN  \n",
       "92751                     0.07039          NaN  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                   object\n",
       "radius_mean                float64\n",
       "texture_mean               float64\n",
       "perimeter_mean             float64\n",
       "area_mean                  float64\n",
       "smoothness_mean            float64\n",
       "compactness_mean           float64\n",
       "concavity_mean             float64\n",
       "concave points_mean        float64\n",
       "symmetry_mean              float64\n",
       "fractal_dimension_mean     float64\n",
       "radius_se                  float64\n",
       "texture_se                 float64\n",
       "perimeter_se               float64\n",
       "area_se                    float64\n",
       "smoothness_se              float64\n",
       "compactness_se             float64\n",
       "concavity_se               float64\n",
       "concave points_se          float64\n",
       "symmetry_se                float64\n",
       "fractal_dimension_se       float64\n",
       "radius_worst               float64\n",
       "texture_worst              float64\n",
       "perimeter_worst            float64\n",
       "area_worst                 float64\n",
       "smoothness_worst           float64\n",
       "compactness_worst          float64\n",
       "concavity_worst            float64\n",
       "concave points_worst       float64\n",
       "symmetry_worst             float64\n",
       "fractal_dimension_worst    float64\n",
       "Unnamed: 32                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Unnamed: 32', axis = 1, inplace = True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 412
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.diagnosis.value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.997855</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.170581</td>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.676764</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.147741</td>\n",
       "      <td>-0.311631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969539</td>\n",
       "      <td>0.297008</td>\n",
       "      <td>0.965137</td>\n",
       "      <td>0.941082</td>\n",
       "      <td>0.119616</td>\n",
       "      <td>0.413463</td>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.163953</td>\n",
       "      <td>0.007066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>0.323782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.329533</td>\n",
       "      <td>0.321086</td>\n",
       "      <td>-0.023389</td>\n",
       "      <td>0.236702</td>\n",
       "      <td>0.302418</td>\n",
       "      <td>0.293464</td>\n",
       "      <td>0.071401</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352573</td>\n",
       "      <td>0.912045</td>\n",
       "      <td>0.358040</td>\n",
       "      <td>0.343546</td>\n",
       "      <td>0.077503</td>\n",
       "      <td>0.277830</td>\n",
       "      <td>0.301025</td>\n",
       "      <td>0.295316</td>\n",
       "      <td>0.105008</td>\n",
       "      <td>0.119205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>0.997855</td>\n",
       "      <td>0.329533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.207278</td>\n",
       "      <td>0.556936</td>\n",
       "      <td>0.716136</td>\n",
       "      <td>0.850977</td>\n",
       "      <td>0.183027</td>\n",
       "      <td>-0.261477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969476</td>\n",
       "      <td>0.303038</td>\n",
       "      <td>0.970387</td>\n",
       "      <td>0.941550</td>\n",
       "      <td>0.150549</td>\n",
       "      <td>0.455774</td>\n",
       "      <td>0.563879</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.189115</td>\n",
       "      <td>0.051019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.321086</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.177028</td>\n",
       "      <td>0.498502</td>\n",
       "      <td>0.685983</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.151293</td>\n",
       "      <td>-0.283110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962746</td>\n",
       "      <td>0.287489</td>\n",
       "      <td>0.959120</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.123523</td>\n",
       "      <td>0.390410</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.722017</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.003738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>0.170581</td>\n",
       "      <td>-0.023389</td>\n",
       "      <td>0.207278</td>\n",
       "      <td>0.177028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659123</td>\n",
       "      <td>0.521984</td>\n",
       "      <td>0.553695</td>\n",
       "      <td>0.557775</td>\n",
       "      <td>0.584792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213120</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.238853</td>\n",
       "      <td>0.206718</td>\n",
       "      <td>0.805324</td>\n",
       "      <td>0.472468</td>\n",
       "      <td>0.434926</td>\n",
       "      <td>0.503053</td>\n",
       "      <td>0.394309</td>\n",
       "      <td>0.499316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.236702</td>\n",
       "      <td>0.556936</td>\n",
       "      <td>0.498502</td>\n",
       "      <td>0.659123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883121</td>\n",
       "      <td>0.831135</td>\n",
       "      <td>0.602641</td>\n",
       "      <td>0.565369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.248133</td>\n",
       "      <td>0.590210</td>\n",
       "      <td>0.509604</td>\n",
       "      <td>0.565541</td>\n",
       "      <td>0.865809</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.815573</td>\n",
       "      <td>0.510223</td>\n",
       "      <td>0.687382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>0.676764</td>\n",
       "      <td>0.302418</td>\n",
       "      <td>0.716136</td>\n",
       "      <td>0.685983</td>\n",
       "      <td>0.521984</td>\n",
       "      <td>0.883121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921391</td>\n",
       "      <td>0.500667</td>\n",
       "      <td>0.336783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688236</td>\n",
       "      <td>0.299879</td>\n",
       "      <td>0.729565</td>\n",
       "      <td>0.675987</td>\n",
       "      <td>0.448822</td>\n",
       "      <td>0.754968</td>\n",
       "      <td>0.884103</td>\n",
       "      <td>0.861323</td>\n",
       "      <td>0.409464</td>\n",
       "      <td>0.514930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.293464</td>\n",
       "      <td>0.850977</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.553695</td>\n",
       "      <td>0.831135</td>\n",
       "      <td>0.921391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.462497</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830318</td>\n",
       "      <td>0.292752</td>\n",
       "      <td>0.855923</td>\n",
       "      <td>0.809630</td>\n",
       "      <td>0.452753</td>\n",
       "      <td>0.667454</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.910155</td>\n",
       "      <td>0.375744</td>\n",
       "      <td>0.368661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>0.147741</td>\n",
       "      <td>0.071401</td>\n",
       "      <td>0.183027</td>\n",
       "      <td>0.151293</td>\n",
       "      <td>0.557775</td>\n",
       "      <td>0.602641</td>\n",
       "      <td>0.500667</td>\n",
       "      <td>0.462497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185728</td>\n",
       "      <td>0.090651</td>\n",
       "      <td>0.219169</td>\n",
       "      <td>0.177193</td>\n",
       "      <td>0.426675</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>0.433721</td>\n",
       "      <td>0.430297</td>\n",
       "      <td>0.699826</td>\n",
       "      <td>0.438413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>-0.311631</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>-0.261477</td>\n",
       "      <td>-0.283110</td>\n",
       "      <td>0.584792</td>\n",
       "      <td>0.565369</td>\n",
       "      <td>0.336783</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>0.479921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>-0.051269</td>\n",
       "      <td>-0.205151</td>\n",
       "      <td>-0.231854</td>\n",
       "      <td>0.504942</td>\n",
       "      <td>0.458798</td>\n",
       "      <td>0.346234</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>0.334019</td>\n",
       "      <td>0.767297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>0.679090</td>\n",
       "      <td>0.275869</td>\n",
       "      <td>0.691765</td>\n",
       "      <td>0.732562</td>\n",
       "      <td>0.301467</td>\n",
       "      <td>0.497473</td>\n",
       "      <td>0.631925</td>\n",
       "      <td>0.698050</td>\n",
       "      <td>0.303379</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715065</td>\n",
       "      <td>0.194799</td>\n",
       "      <td>0.719684</td>\n",
       "      <td>0.751548</td>\n",
       "      <td>0.141919</td>\n",
       "      <td>0.287103</td>\n",
       "      <td>0.380585</td>\n",
       "      <td>0.531062</td>\n",
       "      <td>0.094543</td>\n",
       "      <td>0.049559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>-0.097317</td>\n",
       "      <td>0.386358</td>\n",
       "      <td>-0.086761</td>\n",
       "      <td>-0.066280</td>\n",
       "      <td>0.068406</td>\n",
       "      <td>0.046205</td>\n",
       "      <td>0.076218</td>\n",
       "      <td>0.021480</td>\n",
       "      <td>0.128053</td>\n",
       "      <td>0.164174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111690</td>\n",
       "      <td>0.409003</td>\n",
       "      <td>-0.102242</td>\n",
       "      <td>-0.083195</td>\n",
       "      <td>-0.073658</td>\n",
       "      <td>-0.092439</td>\n",
       "      <td>-0.068956</td>\n",
       "      <td>-0.119638</td>\n",
       "      <td>-0.128215</td>\n",
       "      <td>-0.045655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>0.674172</td>\n",
       "      <td>0.281673</td>\n",
       "      <td>0.693135</td>\n",
       "      <td>0.726628</td>\n",
       "      <td>0.296092</td>\n",
       "      <td>0.548905</td>\n",
       "      <td>0.660391</td>\n",
       "      <td>0.710650</td>\n",
       "      <td>0.313893</td>\n",
       "      <td>0.039830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697201</td>\n",
       "      <td>0.200371</td>\n",
       "      <td>0.721031</td>\n",
       "      <td>0.730713</td>\n",
       "      <td>0.130054</td>\n",
       "      <td>0.341919</td>\n",
       "      <td>0.418899</td>\n",
       "      <td>0.554897</td>\n",
       "      <td>0.109930</td>\n",
       "      <td>0.085433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>0.735864</td>\n",
       "      <td>0.259845</td>\n",
       "      <td>0.744983</td>\n",
       "      <td>0.800086</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>0.455653</td>\n",
       "      <td>0.617427</td>\n",
       "      <td>0.690299</td>\n",
       "      <td>0.223970</td>\n",
       "      <td>-0.090170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757373</td>\n",
       "      <td>0.196497</td>\n",
       "      <td>0.761213</td>\n",
       "      <td>0.811408</td>\n",
       "      <td>0.125389</td>\n",
       "      <td>0.283257</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>0.538166</td>\n",
       "      <td>0.074126</td>\n",
       "      <td>0.017539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>-0.222600</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>-0.202694</td>\n",
       "      <td>-0.166777</td>\n",
       "      <td>0.332375</td>\n",
       "      <td>0.135299</td>\n",
       "      <td>0.098564</td>\n",
       "      <td>0.027653</td>\n",
       "      <td>0.187321</td>\n",
       "      <td>0.401964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230691</td>\n",
       "      <td>-0.074743</td>\n",
       "      <td>-0.217304</td>\n",
       "      <td>-0.182195</td>\n",
       "      <td>0.314457</td>\n",
       "      <td>-0.055558</td>\n",
       "      <td>-0.058298</td>\n",
       "      <td>-0.102007</td>\n",
       "      <td>-0.107342</td>\n",
       "      <td>0.101480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.191975</td>\n",
       "      <td>0.250744</td>\n",
       "      <td>0.212583</td>\n",
       "      <td>0.318943</td>\n",
       "      <td>0.738722</td>\n",
       "      <td>0.670279</td>\n",
       "      <td>0.490424</td>\n",
       "      <td>0.421659</td>\n",
       "      <td>0.559837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204607</td>\n",
       "      <td>0.143003</td>\n",
       "      <td>0.260516</td>\n",
       "      <td>0.199371</td>\n",
       "      <td>0.227394</td>\n",
       "      <td>0.678780</td>\n",
       "      <td>0.639147</td>\n",
       "      <td>0.483208</td>\n",
       "      <td>0.277878</td>\n",
       "      <td>0.590973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>0.194204</td>\n",
       "      <td>0.143293</td>\n",
       "      <td>0.228082</td>\n",
       "      <td>0.207660</td>\n",
       "      <td>0.248396</td>\n",
       "      <td>0.570517</td>\n",
       "      <td>0.691270</td>\n",
       "      <td>0.439167</td>\n",
       "      <td>0.342627</td>\n",
       "      <td>0.446630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186904</td>\n",
       "      <td>0.100241</td>\n",
       "      <td>0.226680</td>\n",
       "      <td>0.188353</td>\n",
       "      <td>0.168481</td>\n",
       "      <td>0.484858</td>\n",
       "      <td>0.662564</td>\n",
       "      <td>0.440472</td>\n",
       "      <td>0.197788</td>\n",
       "      <td>0.439329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_se</th>\n",
       "      <td>0.376169</td>\n",
       "      <td>0.163851</td>\n",
       "      <td>0.407217</td>\n",
       "      <td>0.372320</td>\n",
       "      <td>0.380676</td>\n",
       "      <td>0.642262</td>\n",
       "      <td>0.683260</td>\n",
       "      <td>0.615634</td>\n",
       "      <td>0.393298</td>\n",
       "      <td>0.341198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358127</td>\n",
       "      <td>0.086741</td>\n",
       "      <td>0.394999</td>\n",
       "      <td>0.342271</td>\n",
       "      <td>0.215351</td>\n",
       "      <td>0.452888</td>\n",
       "      <td>0.549592</td>\n",
       "      <td>0.602450</td>\n",
       "      <td>0.143116</td>\n",
       "      <td>0.310655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>-0.104321</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>-0.081629</td>\n",
       "      <td>-0.072497</td>\n",
       "      <td>0.200774</td>\n",
       "      <td>0.229977</td>\n",
       "      <td>0.178009</td>\n",
       "      <td>0.095351</td>\n",
       "      <td>0.449137</td>\n",
       "      <td>0.345007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128121</td>\n",
       "      <td>-0.077473</td>\n",
       "      <td>-0.103753</td>\n",
       "      <td>-0.110343</td>\n",
       "      <td>-0.012662</td>\n",
       "      <td>0.060255</td>\n",
       "      <td>0.037119</td>\n",
       "      <td>-0.030413</td>\n",
       "      <td>0.389402</td>\n",
       "      <td>0.078079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <td>-0.042641</td>\n",
       "      <td>0.054458</td>\n",
       "      <td>-0.005523</td>\n",
       "      <td>-0.019887</td>\n",
       "      <td>0.283607</td>\n",
       "      <td>0.507318</td>\n",
       "      <td>0.449301</td>\n",
       "      <td>0.257584</td>\n",
       "      <td>0.331786</td>\n",
       "      <td>0.688132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037488</td>\n",
       "      <td>-0.003195</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.022736</td>\n",
       "      <td>0.170568</td>\n",
       "      <td>0.390159</td>\n",
       "      <td>0.379975</td>\n",
       "      <td>0.215204</td>\n",
       "      <td>0.111094</td>\n",
       "      <td>0.591328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>0.969539</td>\n",
       "      <td>0.352573</td>\n",
       "      <td>0.969476</td>\n",
       "      <td>0.962746</td>\n",
       "      <td>0.213120</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.688236</td>\n",
       "      <td>0.830318</td>\n",
       "      <td>0.185728</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359921</td>\n",
       "      <td>0.993708</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>0.216574</td>\n",
       "      <td>0.475820</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.787424</td>\n",
       "      <td>0.243529</td>\n",
       "      <td>0.093492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>0.297008</td>\n",
       "      <td>0.912045</td>\n",
       "      <td>0.303038</td>\n",
       "      <td>0.287489</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.248133</td>\n",
       "      <td>0.299879</td>\n",
       "      <td>0.292752</td>\n",
       "      <td>0.090651</td>\n",
       "      <td>-0.051269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.365098</td>\n",
       "      <td>0.345842</td>\n",
       "      <td>0.225429</td>\n",
       "      <td>0.360832</td>\n",
       "      <td>0.368366</td>\n",
       "      <td>0.359755</td>\n",
       "      <td>0.233027</td>\n",
       "      <td>0.219122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>0.965137</td>\n",
       "      <td>0.358040</td>\n",
       "      <td>0.970387</td>\n",
       "      <td>0.959120</td>\n",
       "      <td>0.238853</td>\n",
       "      <td>0.590210</td>\n",
       "      <td>0.729565</td>\n",
       "      <td>0.855923</td>\n",
       "      <td>0.219169</td>\n",
       "      <td>-0.205151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993708</td>\n",
       "      <td>0.365098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.236775</td>\n",
       "      <td>0.529408</td>\n",
       "      <td>0.618344</td>\n",
       "      <td>0.816322</td>\n",
       "      <td>0.269493</td>\n",
       "      <td>0.138957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>0.941082</td>\n",
       "      <td>0.343546</td>\n",
       "      <td>0.941550</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.206718</td>\n",
       "      <td>0.509604</td>\n",
       "      <td>0.675987</td>\n",
       "      <td>0.809630</td>\n",
       "      <td>0.177193</td>\n",
       "      <td>-0.231854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>0.345842</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209145</td>\n",
       "      <td>0.438296</td>\n",
       "      <td>0.543331</td>\n",
       "      <td>0.747419</td>\n",
       "      <td>0.209146</td>\n",
       "      <td>0.079647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>0.119616</td>\n",
       "      <td>0.077503</td>\n",
       "      <td>0.150549</td>\n",
       "      <td>0.123523</td>\n",
       "      <td>0.805324</td>\n",
       "      <td>0.565541</td>\n",
       "      <td>0.448822</td>\n",
       "      <td>0.452753</td>\n",
       "      <td>0.426675</td>\n",
       "      <td>0.504942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216574</td>\n",
       "      <td>0.225429</td>\n",
       "      <td>0.236775</td>\n",
       "      <td>0.209145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.568187</td>\n",
       "      <td>0.518523</td>\n",
       "      <td>0.547691</td>\n",
       "      <td>0.493838</td>\n",
       "      <td>0.617624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>0.413463</td>\n",
       "      <td>0.277830</td>\n",
       "      <td>0.455774</td>\n",
       "      <td>0.390410</td>\n",
       "      <td>0.472468</td>\n",
       "      <td>0.865809</td>\n",
       "      <td>0.754968</td>\n",
       "      <td>0.667454</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>0.458798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475820</td>\n",
       "      <td>0.360832</td>\n",
       "      <td>0.529408</td>\n",
       "      <td>0.438296</td>\n",
       "      <td>0.568187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892261</td>\n",
       "      <td>0.801080</td>\n",
       "      <td>0.614441</td>\n",
       "      <td>0.810455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.301025</td>\n",
       "      <td>0.563879</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.434926</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.884103</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.433721</td>\n",
       "      <td>0.346234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.368366</td>\n",
       "      <td>0.618344</td>\n",
       "      <td>0.543331</td>\n",
       "      <td>0.518523</td>\n",
       "      <td>0.892261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855434</td>\n",
       "      <td>0.532520</td>\n",
       "      <td>0.686511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.295316</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.722017</td>\n",
       "      <td>0.503053</td>\n",
       "      <td>0.815573</td>\n",
       "      <td>0.861323</td>\n",
       "      <td>0.910155</td>\n",
       "      <td>0.430297</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787424</td>\n",
       "      <td>0.359755</td>\n",
       "      <td>0.816322</td>\n",
       "      <td>0.747419</td>\n",
       "      <td>0.547691</td>\n",
       "      <td>0.801080</td>\n",
       "      <td>0.855434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502528</td>\n",
       "      <td>0.511114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>0.163953</td>\n",
       "      <td>0.105008</td>\n",
       "      <td>0.189115</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.394309</td>\n",
       "      <td>0.510223</td>\n",
       "      <td>0.409464</td>\n",
       "      <td>0.375744</td>\n",
       "      <td>0.699826</td>\n",
       "      <td>0.334019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243529</td>\n",
       "      <td>0.233027</td>\n",
       "      <td>0.269493</td>\n",
       "      <td>0.209146</td>\n",
       "      <td>0.493838</td>\n",
       "      <td>0.614441</td>\n",
       "      <td>0.532520</td>\n",
       "      <td>0.502528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.537848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>0.051019</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.499316</td>\n",
       "      <td>0.687382</td>\n",
       "      <td>0.514930</td>\n",
       "      <td>0.368661</td>\n",
       "      <td>0.438413</td>\n",
       "      <td>0.767297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093492</td>\n",
       "      <td>0.219122</td>\n",
       "      <td>0.138957</td>\n",
       "      <td>0.079647</td>\n",
       "      <td>0.617624</td>\n",
       "      <td>0.810455</td>\n",
       "      <td>0.686511</td>\n",
       "      <td>0.511114</td>\n",
       "      <td>0.537848</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "radius_mean                 1.000000      0.323782        0.997855   0.987357   \n",
       "texture_mean                0.323782      1.000000        0.329533   0.321086   \n",
       "perimeter_mean              0.997855      0.329533        1.000000   0.986507   \n",
       "area_mean                   0.987357      0.321086        0.986507   1.000000   \n",
       "smoothness_mean             0.170581     -0.023389        0.207278   0.177028   \n",
       "compactness_mean            0.506124      0.236702        0.556936   0.498502   \n",
       "concavity_mean              0.676764      0.302418        0.716136   0.685983   \n",
       "concave points_mean         0.822529      0.293464        0.850977   0.823269   \n",
       "symmetry_mean               0.147741      0.071401        0.183027   0.151293   \n",
       "fractal_dimension_mean     -0.311631     -0.076437       -0.261477  -0.283110   \n",
       "radius_se                   0.679090      0.275869        0.691765   0.732562   \n",
       "texture_se                 -0.097317      0.386358       -0.086761  -0.066280   \n",
       "perimeter_se                0.674172      0.281673        0.693135   0.726628   \n",
       "area_se                     0.735864      0.259845        0.744983   0.800086   \n",
       "smoothness_se              -0.222600      0.006614       -0.202694  -0.166777   \n",
       "compactness_se              0.206000      0.191975        0.250744   0.212583   \n",
       "concavity_se                0.194204      0.143293        0.228082   0.207660   \n",
       "concave points_se           0.376169      0.163851        0.407217   0.372320   \n",
       "symmetry_se                -0.104321      0.009127       -0.081629  -0.072497   \n",
       "fractal_dimension_se       -0.042641      0.054458       -0.005523  -0.019887   \n",
       "radius_worst                0.969539      0.352573        0.969476   0.962746   \n",
       "texture_worst               0.297008      0.912045        0.303038   0.287489   \n",
       "perimeter_worst             0.965137      0.358040        0.970387   0.959120   \n",
       "area_worst                  0.941082      0.343546        0.941550   0.959213   \n",
       "smoothness_worst            0.119616      0.077503        0.150549   0.123523   \n",
       "compactness_worst           0.413463      0.277830        0.455774   0.390410   \n",
       "concavity_worst             0.526911      0.301025        0.563879   0.512606   \n",
       "concave points_worst        0.744214      0.295316        0.771241   0.722017   \n",
       "symmetry_worst              0.163953      0.105008        0.189115   0.143570   \n",
       "fractal_dimension_worst     0.007066      0.119205        0.051019   0.003738   \n",
       "\n",
       "                         smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "radius_mean                     0.170581          0.506124        0.676764   \n",
       "texture_mean                   -0.023389          0.236702        0.302418   \n",
       "perimeter_mean                  0.207278          0.556936        0.716136   \n",
       "area_mean                       0.177028          0.498502        0.685983   \n",
       "smoothness_mean                 1.000000          0.659123        0.521984   \n",
       "compactness_mean                0.659123          1.000000        0.883121   \n",
       "concavity_mean                  0.521984          0.883121        1.000000   \n",
       "concave points_mean             0.553695          0.831135        0.921391   \n",
       "symmetry_mean                   0.557775          0.602641        0.500667   \n",
       "fractal_dimension_mean          0.584792          0.565369        0.336783   \n",
       "radius_se                       0.301467          0.497473        0.631925   \n",
       "texture_se                      0.068406          0.046205        0.076218   \n",
       "perimeter_se                    0.296092          0.548905        0.660391   \n",
       "area_se                         0.246552          0.455653        0.617427   \n",
       "smoothness_se                   0.332375          0.135299        0.098564   \n",
       "compactness_se                  0.318943          0.738722        0.670279   \n",
       "concavity_se                    0.248396          0.570517        0.691270   \n",
       "concave points_se               0.380676          0.642262        0.683260   \n",
       "symmetry_se                     0.200774          0.229977        0.178009   \n",
       "fractal_dimension_se            0.283607          0.507318        0.449301   \n",
       "radius_worst                    0.213120          0.535315        0.688236   \n",
       "texture_worst                   0.036072          0.248133        0.299879   \n",
       "perimeter_worst                 0.238853          0.590210        0.729565   \n",
       "area_worst                      0.206718          0.509604        0.675987   \n",
       "smoothness_worst                0.805324          0.565541        0.448822   \n",
       "compactness_worst               0.472468          0.865809        0.754968   \n",
       "concavity_worst                 0.434926          0.816275        0.884103   \n",
       "concave points_worst            0.503053          0.815573        0.861323   \n",
       "symmetry_worst                  0.394309          0.510223        0.409464   \n",
       "fractal_dimension_worst         0.499316          0.687382        0.514930   \n",
       "\n",
       "                         concave points_mean  symmetry_mean  \\\n",
       "radius_mean                         0.822529       0.147741   \n",
       "texture_mean                        0.293464       0.071401   \n",
       "perimeter_mean                      0.850977       0.183027   \n",
       "area_mean                           0.823269       0.151293   \n",
       "smoothness_mean                     0.553695       0.557775   \n",
       "compactness_mean                    0.831135       0.602641   \n",
       "concavity_mean                      0.921391       0.500667   \n",
       "concave points_mean                 1.000000       0.462497   \n",
       "symmetry_mean                       0.462497       1.000000   \n",
       "fractal_dimension_mean              0.166917       0.479921   \n",
       "radius_se                           0.698050       0.303379   \n",
       "texture_se                          0.021480       0.128053   \n",
       "perimeter_se                        0.710650       0.313893   \n",
       "area_se                             0.690299       0.223970   \n",
       "smoothness_se                       0.027653       0.187321   \n",
       "compactness_se                      0.490424       0.421659   \n",
       "concavity_se                        0.439167       0.342627   \n",
       "concave points_se                   0.615634       0.393298   \n",
       "symmetry_se                         0.095351       0.449137   \n",
       "fractal_dimension_se                0.257584       0.331786   \n",
       "radius_worst                        0.830318       0.185728   \n",
       "texture_worst                       0.292752       0.090651   \n",
       "perimeter_worst                     0.855923       0.219169   \n",
       "area_worst                          0.809630       0.177193   \n",
       "smoothness_worst                    0.452753       0.426675   \n",
       "compactness_worst                   0.667454       0.473200   \n",
       "concavity_worst                     0.752399       0.433721   \n",
       "concave points_worst                0.910155       0.430297   \n",
       "symmetry_worst                      0.375744       0.699826   \n",
       "fractal_dimension_worst             0.368661       0.438413   \n",
       "\n",
       "                         fractal_dimension_mean  ...  radius_worst  \\\n",
       "radius_mean                           -0.311631  ...      0.969539   \n",
       "texture_mean                          -0.076437  ...      0.352573   \n",
       "perimeter_mean                        -0.261477  ...      0.969476   \n",
       "area_mean                             -0.283110  ...      0.962746   \n",
       "smoothness_mean                        0.584792  ...      0.213120   \n",
       "compactness_mean                       0.565369  ...      0.535315   \n",
       "concavity_mean                         0.336783  ...      0.688236   \n",
       "concave points_mean                    0.166917  ...      0.830318   \n",
       "symmetry_mean                          0.479921  ...      0.185728   \n",
       "fractal_dimension_mean                 1.000000  ...     -0.253691   \n",
       "radius_se                              0.000111  ...      0.715065   \n",
       "texture_se                             0.164174  ...     -0.111690   \n",
       "perimeter_se                           0.039830  ...      0.697201   \n",
       "area_se                               -0.090170  ...      0.757373   \n",
       "smoothness_se                          0.401964  ...     -0.230691   \n",
       "compactness_se                         0.559837  ...      0.204607   \n",
       "concavity_se                           0.446630  ...      0.186904   \n",
       "concave points_se                      0.341198  ...      0.358127   \n",
       "symmetry_se                            0.345007  ...     -0.128121   \n",
       "fractal_dimension_se                   0.688132  ...     -0.037488   \n",
       "radius_worst                          -0.253691  ...      1.000000   \n",
       "texture_worst                         -0.051269  ...      0.359921   \n",
       "perimeter_worst                       -0.205151  ...      0.993708   \n",
       "area_worst                            -0.231854  ...      0.984015   \n",
       "smoothness_worst                       0.504942  ...      0.216574   \n",
       "compactness_worst                      0.458798  ...      0.475820   \n",
       "concavity_worst                        0.346234  ...      0.573975   \n",
       "concave points_worst                   0.175325  ...      0.787424   \n",
       "symmetry_worst                         0.334019  ...      0.243529   \n",
       "fractal_dimension_worst                0.767297  ...      0.093492   \n",
       "\n",
       "                         texture_worst  perimeter_worst  area_worst  \\\n",
       "radius_mean                   0.297008         0.965137    0.941082   \n",
       "texture_mean                  0.912045         0.358040    0.343546   \n",
       "perimeter_mean                0.303038         0.970387    0.941550   \n",
       "area_mean                     0.287489         0.959120    0.959213   \n",
       "smoothness_mean               0.036072         0.238853    0.206718   \n",
       "compactness_mean              0.248133         0.590210    0.509604   \n",
       "concavity_mean                0.299879         0.729565    0.675987   \n",
       "concave points_mean           0.292752         0.855923    0.809630   \n",
       "symmetry_mean                 0.090651         0.219169    0.177193   \n",
       "fractal_dimension_mean       -0.051269        -0.205151   -0.231854   \n",
       "radius_se                     0.194799         0.719684    0.751548   \n",
       "texture_se                    0.409003        -0.102242   -0.083195   \n",
       "perimeter_se                  0.200371         0.721031    0.730713   \n",
       "area_se                       0.196497         0.761213    0.811408   \n",
       "smoothness_se                -0.074743        -0.217304   -0.182195   \n",
       "compactness_se                0.143003         0.260516    0.199371   \n",
       "concavity_se                  0.100241         0.226680    0.188353   \n",
       "concave points_se             0.086741         0.394999    0.342271   \n",
       "symmetry_se                  -0.077473        -0.103753   -0.110343   \n",
       "fractal_dimension_se         -0.003195        -0.001000   -0.022736   \n",
       "radius_worst                  0.359921         0.993708    0.984015   \n",
       "texture_worst                 1.000000         0.365098    0.345842   \n",
       "perimeter_worst               0.365098         1.000000    0.977578   \n",
       "area_worst                    0.345842         0.977578    1.000000   \n",
       "smoothness_worst              0.225429         0.236775    0.209145   \n",
       "compactness_worst             0.360832         0.529408    0.438296   \n",
       "concavity_worst               0.368366         0.618344    0.543331   \n",
       "concave points_worst          0.359755         0.816322    0.747419   \n",
       "symmetry_worst                0.233027         0.269493    0.209146   \n",
       "fractal_dimension_worst       0.219122         0.138957    0.079647   \n",
       "\n",
       "                         smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "radius_mean                      0.119616           0.413463         0.526911   \n",
       "texture_mean                     0.077503           0.277830         0.301025   \n",
       "perimeter_mean                   0.150549           0.455774         0.563879   \n",
       "area_mean                        0.123523           0.390410         0.512606   \n",
       "smoothness_mean                  0.805324           0.472468         0.434926   \n",
       "compactness_mean                 0.565541           0.865809         0.816275   \n",
       "concavity_mean                   0.448822           0.754968         0.884103   \n",
       "concave points_mean              0.452753           0.667454         0.752399   \n",
       "symmetry_mean                    0.426675           0.473200         0.433721   \n",
       "fractal_dimension_mean           0.504942           0.458798         0.346234   \n",
       "radius_se                        0.141919           0.287103         0.380585   \n",
       "texture_se                      -0.073658          -0.092439        -0.068956   \n",
       "perimeter_se                     0.130054           0.341919         0.418899   \n",
       "area_se                          0.125389           0.283257         0.385100   \n",
       "smoothness_se                    0.314457          -0.055558        -0.058298   \n",
       "compactness_se                   0.227394           0.678780         0.639147   \n",
       "concavity_se                     0.168481           0.484858         0.662564   \n",
       "concave points_se                0.215351           0.452888         0.549592   \n",
       "symmetry_se                     -0.012662           0.060255         0.037119   \n",
       "fractal_dimension_se             0.170568           0.390159         0.379975   \n",
       "radius_worst                     0.216574           0.475820         0.573975   \n",
       "texture_worst                    0.225429           0.360832         0.368366   \n",
       "perimeter_worst                  0.236775           0.529408         0.618344   \n",
       "area_worst                       0.209145           0.438296         0.543331   \n",
       "smoothness_worst                 1.000000           0.568187         0.518523   \n",
       "compactness_worst                0.568187           1.000000         0.892261   \n",
       "concavity_worst                  0.518523           0.892261         1.000000   \n",
       "concave points_worst             0.547691           0.801080         0.855434   \n",
       "symmetry_worst                   0.493838           0.614441         0.532520   \n",
       "fractal_dimension_worst          0.617624           0.810455         0.686511   \n",
       "\n",
       "                         concave points_worst  symmetry_worst  \\\n",
       "radius_mean                          0.744214        0.163953   \n",
       "texture_mean                         0.295316        0.105008   \n",
       "perimeter_mean                       0.771241        0.189115   \n",
       "area_mean                            0.722017        0.143570   \n",
       "smoothness_mean                      0.503053        0.394309   \n",
       "compactness_mean                     0.815573        0.510223   \n",
       "concavity_mean                       0.861323        0.409464   \n",
       "concave points_mean                  0.910155        0.375744   \n",
       "symmetry_mean                        0.430297        0.699826   \n",
       "fractal_dimension_mean               0.175325        0.334019   \n",
       "radius_se                            0.531062        0.094543   \n",
       "texture_se                          -0.119638       -0.128215   \n",
       "perimeter_se                         0.554897        0.109930   \n",
       "area_se                              0.538166        0.074126   \n",
       "smoothness_se                       -0.102007       -0.107342   \n",
       "compactness_se                       0.483208        0.277878   \n",
       "concavity_se                         0.440472        0.197788   \n",
       "concave points_se                    0.602450        0.143116   \n",
       "symmetry_se                         -0.030413        0.389402   \n",
       "fractal_dimension_se                 0.215204        0.111094   \n",
       "radius_worst                         0.787424        0.243529   \n",
       "texture_worst                        0.359755        0.233027   \n",
       "perimeter_worst                      0.816322        0.269493   \n",
       "area_worst                           0.747419        0.209146   \n",
       "smoothness_worst                     0.547691        0.493838   \n",
       "compactness_worst                    0.801080        0.614441   \n",
       "concavity_worst                      0.855434        0.532520   \n",
       "concave points_worst                 1.000000        0.502528   \n",
       "symmetry_worst                       0.502528        1.000000   \n",
       "fractal_dimension_worst              0.511114        0.537848   \n",
       "\n",
       "                         fractal_dimension_worst  \n",
       "radius_mean                             0.007066  \n",
       "texture_mean                            0.119205  \n",
       "perimeter_mean                          0.051019  \n",
       "area_mean                               0.003738  \n",
       "smoothness_mean                         0.499316  \n",
       "compactness_mean                        0.687382  \n",
       "concavity_mean                          0.514930  \n",
       "concave points_mean                     0.368661  \n",
       "symmetry_mean                           0.438413  \n",
       "fractal_dimension_mean                  0.767297  \n",
       "radius_se                               0.049559  \n",
       "texture_se                             -0.045655  \n",
       "perimeter_se                            0.085433  \n",
       "area_se                                 0.017539  \n",
       "smoothness_se                           0.101480  \n",
       "compactness_se                          0.590973  \n",
       "concavity_se                            0.439329  \n",
       "concave points_se                       0.310655  \n",
       "symmetry_se                             0.078079  \n",
       "fractal_dimension_se                    0.591328  \n",
       "radius_worst                            0.093492  \n",
       "texture_worst                           0.219122  \n",
       "perimeter_worst                         0.138957  \n",
       "area_worst                              0.079647  \n",
       "smoothness_worst                        0.617624  \n",
       "compactness_worst                       0.810455  \n",
       "concavity_worst                         0.686511  \n",
       "concave points_worst                    0.511114  \n",
       "symmetry_worst                          0.537848  \n",
       "fractal_dimension_worst                 1.000000  \n",
       "\n",
       "[30 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Omwx5vVbYKeo"
   },
   "source": [
    "### 3. Logistic Regression Model\n",
    "\n",
    "#### 3.1 Use Logistic Regression\n",
    "\n",
    "Use Logistic Regression and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']]\n",
    "y = df.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'M',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standard scale X_train amd x_test and \n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# create Model and fit scaled predictors\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(scaled_X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(scaled_X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      0.99      0.98        72\n",
      "           M       0.98      0.95      0.96        42\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71  1]\n",
      " [ 2 40]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mogg_w8vYKep"
   },
   "source": [
    "### 4. Support Vector Machine\n",
    "\n",
    "#### 4.1 Use Support Vector Machine\n",
    "\n",
    "Use Support Vector Machine and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']]\n",
    "y = df.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'M',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standard scale X_train amd x_test and \n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "#Import svm model\n",
    "\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear', random_state = 45, probability = True,  ) # rbf Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(scaled_X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(scaled_X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9824561403508771"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      1.00      0.99        72\n",
      "           M       1.00      0.95      0.98        42\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72  0]\n",
      " [ 2 40]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdzQkTb7YKeq"
   },
   "source": [
    "### 5. Naive Bayes\n",
    "#### 5.1 Use Naive Bayes\n",
    "\n",
    "Use Naive Bayes and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']]\n",
    "y = df.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard scale X_train amd x_test and \n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'M',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M'], dtype='<U1')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets \n",
    "model.fit(scaled_X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298245614035088"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.93      0.96      0.95        72\n",
      "           M       0.93      0.88      0.90        42\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69  3]\n",
      " [ 5 37]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoGxthaeYKer"
   },
   "source": [
    "### 6 Gridsearch optimal parameters for all three models.\n",
    "\n",
    "Is there any difference between accuracy score of Logistic Regression and SVM? Use grid serach to find optimal parameter for both these models.\n",
    "\n",
    "> Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. Typical examples include C, kernel and gamma for Support Vector Classifier, alpha for Lasso, etc.\n",
    "\n",
    "> It is possible and recommended to search the hyper-parameter space for the best cross validation score.\n",
    "\n",
    "> https://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "\n",
    "**Note:** It'll take time to execute this. After running the cell, wait for result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UeqrbsyNYKes"
   },
   "source": [
    "#### 6.1 Find Best Estimator For Logistic Regression \n",
    "\n",
    "Find out how these parameters effect model. Find out the best estimator, score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [c for c in df.columns if c != 'diagnosis']\n",
    "X = df[feature_columns]\n",
    "y = df.diagnosis\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 45)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.fit_transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:40:29.397881Z",
     "start_time": "2019-05-09T05:40:29.392602Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UkQ9RBQZYKet"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.94285714        nan 0.94505495        nan 0.95384615]\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 10, 100], 'penalty': ['l1', 'l2']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_params = {\n",
    "    'penalty': ['l1','l2'],\n",
    "    'C': [1, 10, 100]\n",
    "}\n",
    "\n",
    "lr_gs = GridSearchCV(LogisticRegression(), lr_params, cv = 5, verbose = 2)\n",
    "lr_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'penalty': 'l2'}\n",
      "0.9538461538461538\n"
     ]
    }
   ],
   "source": [
    "best_svc = lr_gs.best_estimator_\n",
    "print(lr_gs.best_params_)\n",
    "print(lr_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:23:14.036840Z",
     "start_time": "2019-05-09T05:23:14.032847Z"
    },
    "colab_type": "text",
    "id": "ioLgY3bxYKev"
   },
   "source": [
    "#### 6.2 Find Best Estimator For SVM\n",
    "\n",
    "Find out how these parameters effect model. Find out the best estimator, score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:40:31.617090Z",
     "start_time": "2019-05-09T05:40:31.612996Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "vgi61VpWYKew"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   3.1s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   2.2s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   3.3s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   3.8s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   3.4s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   5.0s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   2.6s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   3.0s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   3.7s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   5.1s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   8.9s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=  12.3s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=  14.8s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   6.2s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=  11.5s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=  14.7s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=  15.4s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=  15.3s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=   7.5s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=  15.1s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=  35.1s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=  19.2s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=  24.1s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=  13.1s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=  28.2s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=  16.4s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=  29.7s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=  26.4s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=  24.3s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=  27.3s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(probability=True),\n",
       "             param_grid={'C': [1, 10, 100], 'gamma': [0.001, 0.0001],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_params = {\n",
    "    'C': [1, 10, 100],\n",
    "    'gamma': [0.001, 0.0001],\n",
    "    'kernel': ['linear','rbf']\n",
    "}\n",
    "\n",
    "svc_gs = GridSearchCV(svm.SVC(probability = True), svc_params, cv = 5, verbose = 2)\n",
    "svc_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.9648351648351647\n"
     ]
    }
   ],
   "source": [
    "best_svc = svc_gs.best_estimator_\n",
    "print(svc_gs.best_params_)\n",
    "print(svc_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:23:59.157703Z",
     "start_time": "2019-05-09T05:23:59.153713Z"
    },
    "colab_type": "text",
    "id": "HrS04DfuYKez"
   },
   "source": [
    "#### 6.3 Plot the ROC curve for the SVM, Logistic Regressions and Naive Bayes on the same plot\n",
    "\n",
    "Find out which model performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 611,
       "width": 689
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat_pp_lin = lr_gs.predict_proba(X_test)\n",
    "yhat_pp = svc_gs.predict_proba(X_test)\n",
    "yhat_pp_nb = nb.predict_proba(scaled_X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, yhat_pp_lin[:,1], pos_label='M')\n",
    "fpr_svc, tpr_svc, _ = roc_curve(y_test, yhat_pp[:,1], pos_label='M')\n",
    "fpr_nb, tpr_nb, _ = roc_curve(y_test, yhat_pp_nb[:,1], pos_label='M')\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve Logistic (area = %0.2f)' % auc(fpr, tpr), linewidth=4)\n",
    "plt.plot(fpr_svc, tpr_svc, label='ROC curve SVC (area = %0.2f)' % auc(fpr_svc, tpr_svc), linewidth=4, color='darkred')\n",
    "plt.plot(fpr_nb, tpr_nb, label='ROC curve NB (area = %0.2f)' % auc(fpr_nb, tpr_nb), linewidth=4, color='darkblue')\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Receiver operating characteristic: M', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WrSrz3AAYKe3"
   },
   "source": [
    "### 7. [BONUS] Learning Curve\n",
    "\n",
    "A learning curve shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much we benefit from adding more training data and whether the estimator suffers more from a variance error or a bias error. If both the validation score and the training score converge to a value that is too low with increasing size of the training set, we will not benefit much from more training data.\n",
    "\n",
    "Plot \"learning curves\" for the best models of each. This is a great way see how training/testing size affects the scores. Look at the documentation for how to use this function in sklearn.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/learning_curve.html#learning-curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:22:19.657638Z",
     "start_time": "2019-05-09T05:22:19.653657Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3Zleg5E-YKe4"
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE8SgkpSYKe7"
   },
   "source": [
    "**References**\n",
    "\n",
    "[Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/downloads/breast-cancer-wisconsin-data.zip/2)\n",
    "\n",
    "[Validation curves: plotting scores to evaluate models](https://scikit-learn.org/stable/modules/learning_curve.html#learning-curves)\n",
    "\n",
    "[In-Depth: Support Vector Machines](https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html)\n",
    "\n",
    "[Understanding Support Vector Machine algorithm from examples (along with code)](https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/)\n",
    "\n",
    "[Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > Â© 2021 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IOD_Lab_5_3_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
