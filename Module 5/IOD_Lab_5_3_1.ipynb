{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XebDJ3UnS3n3"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_-HjrL6S3n5"
   },
   "source": [
    "# Lab 5.3.1 \n",
    "# *Support Vector Machines*\n",
    "\n",
    "SVMs use linear algebra to find an (n-1)-dimensional boundary that separates classes within an n-dimensional space. In practical terms, this technique provides a conceptually simple way to predict class membership from a set of features. \n",
    "\n",
    "The standard (linear) SVM is immediately applicable to linear classification problems. Furthermore, by applying transformations to the feature space it is possible to tackle nonlinear classificaiton problems. These transforms are called *kernels*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azVVNUxHYKej"
   },
   "source": [
    "### 1. Load Data\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1) ID number 2) Diagnosis (M = malignant, B = benign) 3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter) b) texture (standard deviation of gray-scale values) c) perimeter d) area e) smoothness (local variation in radius lengths) f) compactness (perimeter^2 / area - 1.0) g) concavity (severity of concave portions of the contour) h) concave points (number of concave portions of the contour) i) symmetry j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "All feature values are recoded with four significant digits.\n",
    "\n",
    "Missing attribute values: none\n",
    "\n",
    "Class distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:13:16.458182Z",
     "start_time": "2019-05-09T05:13:16.454244Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "aICmn_7xYKek"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/dmuwa/OneDrive/Documents/1.IoD/Data_Set/data/data/breast-cancer-wisconsin-data.csv\", index_col = \"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FPRqG96QYKen"
   },
   "source": [
    "### 2. EDA \n",
    "\n",
    "- Explore dataset. Clean data (if required)\n",
    "- Find features to predict class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926424</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926682</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926954</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927241</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92751</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "id                                                                         \n",
       "842302           M        17.99         10.38          122.80     1001.0   \n",
       "842517           M        20.57         17.77          132.90     1326.0   \n",
       "84300903         M        19.69         21.25          130.00     1203.0   \n",
       "84348301         M        11.42         20.38           77.58      386.1   \n",
       "84358402         M        20.29         14.34          135.10     1297.0   \n",
       "...            ...          ...           ...             ...        ...   \n",
       "926424           M        21.56         22.39          142.00     1479.0   \n",
       "926682           M        20.13         28.25          131.20     1261.0   \n",
       "926954           M        16.60         28.08          108.30      858.1   \n",
       "927241           M        20.60         29.33          140.10     1265.0   \n",
       "92751            B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "          smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "id                                                            \n",
       "842302            0.11840           0.27760         0.30010   \n",
       "842517            0.08474           0.07864         0.08690   \n",
       "84300903          0.10960           0.15990         0.19740   \n",
       "84348301          0.14250           0.28390         0.24140   \n",
       "84358402          0.10030           0.13280         0.19800   \n",
       "...                   ...               ...             ...   \n",
       "926424            0.11100           0.11590         0.24390   \n",
       "926682            0.09780           0.10340         0.14400   \n",
       "926954            0.08455           0.10230         0.09251   \n",
       "927241            0.11780           0.27700         0.35140   \n",
       "92751             0.05263           0.04362         0.00000   \n",
       "\n",
       "          concave points_mean  symmetry_mean  ...  texture_worst  \\\n",
       "id                                            ...                  \n",
       "842302                0.14710         0.2419  ...          17.33   \n",
       "842517                0.07017         0.1812  ...          23.41   \n",
       "84300903              0.12790         0.2069  ...          25.53   \n",
       "84348301              0.10520         0.2597  ...          26.50   \n",
       "84358402              0.10430         0.1809  ...          16.67   \n",
       "...                       ...            ...  ...            ...   \n",
       "926424                0.13890         0.1726  ...          26.40   \n",
       "926682                0.09791         0.1752  ...          38.25   \n",
       "926954                0.05302         0.1590  ...          34.12   \n",
       "927241                0.15200         0.2397  ...          39.42   \n",
       "92751                 0.00000         0.1587  ...          30.37   \n",
       "\n",
       "          perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "id                                                                           \n",
       "842302             184.60      2019.0           0.16220            0.66560   \n",
       "842517             158.80      1956.0           0.12380            0.18660   \n",
       "84300903           152.50      1709.0           0.14440            0.42450   \n",
       "84348301            98.87       567.7           0.20980            0.86630   \n",
       "84358402           152.20      1575.0           0.13740            0.20500   \n",
       "...                   ...         ...               ...                ...   \n",
       "926424             166.10      2027.0           0.14100            0.21130   \n",
       "926682             155.00      1731.0           0.11660            0.19220   \n",
       "926954             126.70      1124.0           0.11390            0.30940   \n",
       "927241             184.60      1821.0           0.16500            0.86810   \n",
       "92751               59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "          concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "id                                                                \n",
       "842302             0.7119                0.2654          0.4601   \n",
       "842517             0.2416                0.1860          0.2750   \n",
       "84300903           0.4504                0.2430          0.3613   \n",
       "84348301           0.6869                0.2575          0.6638   \n",
       "84358402           0.4000                0.1625          0.2364   \n",
       "...                   ...                   ...             ...   \n",
       "926424             0.4107                0.2216          0.2060   \n",
       "926682             0.3215                0.1628          0.2572   \n",
       "926954             0.3403                0.1418          0.2218   \n",
       "927241             0.9387                0.2650          0.4087   \n",
       "92751              0.0000                0.0000          0.2871   \n",
       "\n",
       "          fractal_dimension_worst  Unnamed: 32  \n",
       "id                                              \n",
       "842302                    0.11890          NaN  \n",
       "842517                    0.08902          NaN  \n",
       "84300903                  0.08758          NaN  \n",
       "84348301                  0.17300          NaN  \n",
       "84358402                  0.07678          NaN  \n",
       "...                           ...          ...  \n",
       "926424                    0.07115          NaN  \n",
       "926682                    0.06637          NaN  \n",
       "926954                    0.07820          NaN  \n",
       "927241                    0.12400          NaN  \n",
       "92751                     0.07039          NaN  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                   object\n",
       "radius_mean                float64\n",
       "texture_mean               float64\n",
       "perimeter_mean             float64\n",
       "area_mean                  float64\n",
       "smoothness_mean            float64\n",
       "compactness_mean           float64\n",
       "concavity_mean             float64\n",
       "concave points_mean        float64\n",
       "symmetry_mean              float64\n",
       "fractal_dimension_mean     float64\n",
       "radius_se                  float64\n",
       "texture_se                 float64\n",
       "perimeter_se               float64\n",
       "area_se                    float64\n",
       "smoothness_se              float64\n",
       "compactness_se             float64\n",
       "concavity_se               float64\n",
       "concave points_se          float64\n",
       "symmetry_se                float64\n",
       "fractal_dimension_se       float64\n",
       "radius_worst               float64\n",
       "texture_worst              float64\n",
       "perimeter_worst            float64\n",
       "area_worst                 float64\n",
       "smoothness_worst           float64\n",
       "compactness_worst          float64\n",
       "concavity_worst            float64\n",
       "concave points_worst       float64\n",
       "symmetry_worst             float64\n",
       "fractal_dimension_worst    float64\n",
       "Unnamed: 32                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Unnamed: 32', axis = 1, inplace = True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 244,
       "width": 412
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.diagnosis.value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323782</td>\n",
       "      <td>0.997855</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.170581</td>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.676764</td>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.147741</td>\n",
       "      <td>-0.311631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969539</td>\n",
       "      <td>0.297008</td>\n",
       "      <td>0.965137</td>\n",
       "      <td>0.941082</td>\n",
       "      <td>0.119616</td>\n",
       "      <td>0.413463</td>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.163953</td>\n",
       "      <td>0.007066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>0.323782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.329533</td>\n",
       "      <td>0.321086</td>\n",
       "      <td>-0.023389</td>\n",
       "      <td>0.236702</td>\n",
       "      <td>0.302418</td>\n",
       "      <td>0.293464</td>\n",
       "      <td>0.071401</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352573</td>\n",
       "      <td>0.912045</td>\n",
       "      <td>0.358040</td>\n",
       "      <td>0.343546</td>\n",
       "      <td>0.077503</td>\n",
       "      <td>0.277830</td>\n",
       "      <td>0.301025</td>\n",
       "      <td>0.295316</td>\n",
       "      <td>0.105008</td>\n",
       "      <td>0.119205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>0.997855</td>\n",
       "      <td>0.329533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>0.207278</td>\n",
       "      <td>0.556936</td>\n",
       "      <td>0.716136</td>\n",
       "      <td>0.850977</td>\n",
       "      <td>0.183027</td>\n",
       "      <td>-0.261477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969476</td>\n",
       "      <td>0.303038</td>\n",
       "      <td>0.970387</td>\n",
       "      <td>0.941550</td>\n",
       "      <td>0.150549</td>\n",
       "      <td>0.455774</td>\n",
       "      <td>0.563879</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.189115</td>\n",
       "      <td>0.051019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_mean</th>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.321086</td>\n",
       "      <td>0.986507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.177028</td>\n",
       "      <td>0.498502</td>\n",
       "      <td>0.685983</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.151293</td>\n",
       "      <td>-0.283110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962746</td>\n",
       "      <td>0.287489</td>\n",
       "      <td>0.959120</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.123523</td>\n",
       "      <td>0.390410</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.722017</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.003738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>0.170581</td>\n",
       "      <td>-0.023389</td>\n",
       "      <td>0.207278</td>\n",
       "      <td>0.177028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659123</td>\n",
       "      <td>0.521984</td>\n",
       "      <td>0.553695</td>\n",
       "      <td>0.557775</td>\n",
       "      <td>0.584792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213120</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.238853</td>\n",
       "      <td>0.206718</td>\n",
       "      <td>0.805324</td>\n",
       "      <td>0.472468</td>\n",
       "      <td>0.434926</td>\n",
       "      <td>0.503053</td>\n",
       "      <td>0.394309</td>\n",
       "      <td>0.499316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.236702</td>\n",
       "      <td>0.556936</td>\n",
       "      <td>0.498502</td>\n",
       "      <td>0.659123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883121</td>\n",
       "      <td>0.831135</td>\n",
       "      <td>0.602641</td>\n",
       "      <td>0.565369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.248133</td>\n",
       "      <td>0.590210</td>\n",
       "      <td>0.509604</td>\n",
       "      <td>0.565541</td>\n",
       "      <td>0.865809</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.815573</td>\n",
       "      <td>0.510223</td>\n",
       "      <td>0.687382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>0.676764</td>\n",
       "      <td>0.302418</td>\n",
       "      <td>0.716136</td>\n",
       "      <td>0.685983</td>\n",
       "      <td>0.521984</td>\n",
       "      <td>0.883121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921391</td>\n",
       "      <td>0.500667</td>\n",
       "      <td>0.336783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688236</td>\n",
       "      <td>0.299879</td>\n",
       "      <td>0.729565</td>\n",
       "      <td>0.675987</td>\n",
       "      <td>0.448822</td>\n",
       "      <td>0.754968</td>\n",
       "      <td>0.884103</td>\n",
       "      <td>0.861323</td>\n",
       "      <td>0.409464</td>\n",
       "      <td>0.514930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_mean</th>\n",
       "      <td>0.822529</td>\n",
       "      <td>0.293464</td>\n",
       "      <td>0.850977</td>\n",
       "      <td>0.823269</td>\n",
       "      <td>0.553695</td>\n",
       "      <td>0.831135</td>\n",
       "      <td>0.921391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.462497</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830318</td>\n",
       "      <td>0.292752</td>\n",
       "      <td>0.855923</td>\n",
       "      <td>0.809630</td>\n",
       "      <td>0.452753</td>\n",
       "      <td>0.667454</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.910155</td>\n",
       "      <td>0.375744</td>\n",
       "      <td>0.368661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_mean</th>\n",
       "      <td>0.147741</td>\n",
       "      <td>0.071401</td>\n",
       "      <td>0.183027</td>\n",
       "      <td>0.151293</td>\n",
       "      <td>0.557775</td>\n",
       "      <td>0.602641</td>\n",
       "      <td>0.500667</td>\n",
       "      <td>0.462497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185728</td>\n",
       "      <td>0.090651</td>\n",
       "      <td>0.219169</td>\n",
       "      <td>0.177193</td>\n",
       "      <td>0.426675</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>0.433721</td>\n",
       "      <td>0.430297</td>\n",
       "      <td>0.699826</td>\n",
       "      <td>0.438413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <td>-0.311631</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>-0.261477</td>\n",
       "      <td>-0.283110</td>\n",
       "      <td>0.584792</td>\n",
       "      <td>0.565369</td>\n",
       "      <td>0.336783</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>0.479921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>-0.051269</td>\n",
       "      <td>-0.205151</td>\n",
       "      <td>-0.231854</td>\n",
       "      <td>0.504942</td>\n",
       "      <td>0.458798</td>\n",
       "      <td>0.346234</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>0.334019</td>\n",
       "      <td>0.767297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>0.679090</td>\n",
       "      <td>0.275869</td>\n",
       "      <td>0.691765</td>\n",
       "      <td>0.732562</td>\n",
       "      <td>0.301467</td>\n",
       "      <td>0.497473</td>\n",
       "      <td>0.631925</td>\n",
       "      <td>0.698050</td>\n",
       "      <td>0.303379</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715065</td>\n",
       "      <td>0.194799</td>\n",
       "      <td>0.719684</td>\n",
       "      <td>0.751548</td>\n",
       "      <td>0.141919</td>\n",
       "      <td>0.287103</td>\n",
       "      <td>0.380585</td>\n",
       "      <td>0.531062</td>\n",
       "      <td>0.094543</td>\n",
       "      <td>0.049559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>-0.097317</td>\n",
       "      <td>0.386358</td>\n",
       "      <td>-0.086761</td>\n",
       "      <td>-0.066280</td>\n",
       "      <td>0.068406</td>\n",
       "      <td>0.046205</td>\n",
       "      <td>0.076218</td>\n",
       "      <td>0.021480</td>\n",
       "      <td>0.128053</td>\n",
       "      <td>0.164174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111690</td>\n",
       "      <td>0.409003</td>\n",
       "      <td>-0.102242</td>\n",
       "      <td>-0.083195</td>\n",
       "      <td>-0.073658</td>\n",
       "      <td>-0.092439</td>\n",
       "      <td>-0.068956</td>\n",
       "      <td>-0.119638</td>\n",
       "      <td>-0.128215</td>\n",
       "      <td>-0.045655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_se</th>\n",
       "      <td>0.674172</td>\n",
       "      <td>0.281673</td>\n",
       "      <td>0.693135</td>\n",
       "      <td>0.726628</td>\n",
       "      <td>0.296092</td>\n",
       "      <td>0.548905</td>\n",
       "      <td>0.660391</td>\n",
       "      <td>0.710650</td>\n",
       "      <td>0.313893</td>\n",
       "      <td>0.039830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697201</td>\n",
       "      <td>0.200371</td>\n",
       "      <td>0.721031</td>\n",
       "      <td>0.730713</td>\n",
       "      <td>0.130054</td>\n",
       "      <td>0.341919</td>\n",
       "      <td>0.418899</td>\n",
       "      <td>0.554897</td>\n",
       "      <td>0.109930</td>\n",
       "      <td>0.085433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_se</th>\n",
       "      <td>0.735864</td>\n",
       "      <td>0.259845</td>\n",
       "      <td>0.744983</td>\n",
       "      <td>0.800086</td>\n",
       "      <td>0.246552</td>\n",
       "      <td>0.455653</td>\n",
       "      <td>0.617427</td>\n",
       "      <td>0.690299</td>\n",
       "      <td>0.223970</td>\n",
       "      <td>-0.090170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757373</td>\n",
       "      <td>0.196497</td>\n",
       "      <td>0.761213</td>\n",
       "      <td>0.811408</td>\n",
       "      <td>0.125389</td>\n",
       "      <td>0.283257</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>0.538166</td>\n",
       "      <td>0.074126</td>\n",
       "      <td>0.017539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_se</th>\n",
       "      <td>-0.222600</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>-0.202694</td>\n",
       "      <td>-0.166777</td>\n",
       "      <td>0.332375</td>\n",
       "      <td>0.135299</td>\n",
       "      <td>0.098564</td>\n",
       "      <td>0.027653</td>\n",
       "      <td>0.187321</td>\n",
       "      <td>0.401964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230691</td>\n",
       "      <td>-0.074743</td>\n",
       "      <td>-0.217304</td>\n",
       "      <td>-0.182195</td>\n",
       "      <td>0.314457</td>\n",
       "      <td>-0.055558</td>\n",
       "      <td>-0.058298</td>\n",
       "      <td>-0.102007</td>\n",
       "      <td>-0.107342</td>\n",
       "      <td>0.101480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>0.206000</td>\n",
       "      <td>0.191975</td>\n",
       "      <td>0.250744</td>\n",
       "      <td>0.212583</td>\n",
       "      <td>0.318943</td>\n",
       "      <td>0.738722</td>\n",
       "      <td>0.670279</td>\n",
       "      <td>0.490424</td>\n",
       "      <td>0.421659</td>\n",
       "      <td>0.559837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204607</td>\n",
       "      <td>0.143003</td>\n",
       "      <td>0.260516</td>\n",
       "      <td>0.199371</td>\n",
       "      <td>0.227394</td>\n",
       "      <td>0.678780</td>\n",
       "      <td>0.639147</td>\n",
       "      <td>0.483208</td>\n",
       "      <td>0.277878</td>\n",
       "      <td>0.590973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_se</th>\n",
       "      <td>0.194204</td>\n",
       "      <td>0.143293</td>\n",
       "      <td>0.228082</td>\n",
       "      <td>0.207660</td>\n",
       "      <td>0.248396</td>\n",
       "      <td>0.570517</td>\n",
       "      <td>0.691270</td>\n",
       "      <td>0.439167</td>\n",
       "      <td>0.342627</td>\n",
       "      <td>0.446630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186904</td>\n",
       "      <td>0.100241</td>\n",
       "      <td>0.226680</td>\n",
       "      <td>0.188353</td>\n",
       "      <td>0.168481</td>\n",
       "      <td>0.484858</td>\n",
       "      <td>0.662564</td>\n",
       "      <td>0.440472</td>\n",
       "      <td>0.197788</td>\n",
       "      <td>0.439329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_se</th>\n",
       "      <td>0.376169</td>\n",
       "      <td>0.163851</td>\n",
       "      <td>0.407217</td>\n",
       "      <td>0.372320</td>\n",
       "      <td>0.380676</td>\n",
       "      <td>0.642262</td>\n",
       "      <td>0.683260</td>\n",
       "      <td>0.615634</td>\n",
       "      <td>0.393298</td>\n",
       "      <td>0.341198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358127</td>\n",
       "      <td>0.086741</td>\n",
       "      <td>0.394999</td>\n",
       "      <td>0.342271</td>\n",
       "      <td>0.215351</td>\n",
       "      <td>0.452888</td>\n",
       "      <td>0.549592</td>\n",
       "      <td>0.602450</td>\n",
       "      <td>0.143116</td>\n",
       "      <td>0.310655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_se</th>\n",
       "      <td>-0.104321</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>-0.081629</td>\n",
       "      <td>-0.072497</td>\n",
       "      <td>0.200774</td>\n",
       "      <td>0.229977</td>\n",
       "      <td>0.178009</td>\n",
       "      <td>0.095351</td>\n",
       "      <td>0.449137</td>\n",
       "      <td>0.345007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128121</td>\n",
       "      <td>-0.077473</td>\n",
       "      <td>-0.103753</td>\n",
       "      <td>-0.110343</td>\n",
       "      <td>-0.012662</td>\n",
       "      <td>0.060255</td>\n",
       "      <td>0.037119</td>\n",
       "      <td>-0.030413</td>\n",
       "      <td>0.389402</td>\n",
       "      <td>0.078079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <td>-0.042641</td>\n",
       "      <td>0.054458</td>\n",
       "      <td>-0.005523</td>\n",
       "      <td>-0.019887</td>\n",
       "      <td>0.283607</td>\n",
       "      <td>0.507318</td>\n",
       "      <td>0.449301</td>\n",
       "      <td>0.257584</td>\n",
       "      <td>0.331786</td>\n",
       "      <td>0.688132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037488</td>\n",
       "      <td>-0.003195</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.022736</td>\n",
       "      <td>0.170568</td>\n",
       "      <td>0.390159</td>\n",
       "      <td>0.379975</td>\n",
       "      <td>0.215204</td>\n",
       "      <td>0.111094</td>\n",
       "      <td>0.591328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>0.969539</td>\n",
       "      <td>0.352573</td>\n",
       "      <td>0.969476</td>\n",
       "      <td>0.962746</td>\n",
       "      <td>0.213120</td>\n",
       "      <td>0.535315</td>\n",
       "      <td>0.688236</td>\n",
       "      <td>0.830318</td>\n",
       "      <td>0.185728</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359921</td>\n",
       "      <td>0.993708</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>0.216574</td>\n",
       "      <td>0.475820</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.787424</td>\n",
       "      <td>0.243529</td>\n",
       "      <td>0.093492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>0.297008</td>\n",
       "      <td>0.912045</td>\n",
       "      <td>0.303038</td>\n",
       "      <td>0.287489</td>\n",
       "      <td>0.036072</td>\n",
       "      <td>0.248133</td>\n",
       "      <td>0.299879</td>\n",
       "      <td>0.292752</td>\n",
       "      <td>0.090651</td>\n",
       "      <td>-0.051269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359921</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.365098</td>\n",
       "      <td>0.345842</td>\n",
       "      <td>0.225429</td>\n",
       "      <td>0.360832</td>\n",
       "      <td>0.368366</td>\n",
       "      <td>0.359755</td>\n",
       "      <td>0.233027</td>\n",
       "      <td>0.219122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_worst</th>\n",
       "      <td>0.965137</td>\n",
       "      <td>0.358040</td>\n",
       "      <td>0.970387</td>\n",
       "      <td>0.959120</td>\n",
       "      <td>0.238853</td>\n",
       "      <td>0.590210</td>\n",
       "      <td>0.729565</td>\n",
       "      <td>0.855923</td>\n",
       "      <td>0.219169</td>\n",
       "      <td>-0.205151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993708</td>\n",
       "      <td>0.365098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.236775</td>\n",
       "      <td>0.529408</td>\n",
       "      <td>0.618344</td>\n",
       "      <td>0.816322</td>\n",
       "      <td>0.269493</td>\n",
       "      <td>0.138957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>0.941082</td>\n",
       "      <td>0.343546</td>\n",
       "      <td>0.941550</td>\n",
       "      <td>0.959213</td>\n",
       "      <td>0.206718</td>\n",
       "      <td>0.509604</td>\n",
       "      <td>0.675987</td>\n",
       "      <td>0.809630</td>\n",
       "      <td>0.177193</td>\n",
       "      <td>-0.231854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>0.345842</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209145</td>\n",
       "      <td>0.438296</td>\n",
       "      <td>0.543331</td>\n",
       "      <td>0.747419</td>\n",
       "      <td>0.209146</td>\n",
       "      <td>0.079647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_worst</th>\n",
       "      <td>0.119616</td>\n",
       "      <td>0.077503</td>\n",
       "      <td>0.150549</td>\n",
       "      <td>0.123523</td>\n",
       "      <td>0.805324</td>\n",
       "      <td>0.565541</td>\n",
       "      <td>0.448822</td>\n",
       "      <td>0.452753</td>\n",
       "      <td>0.426675</td>\n",
       "      <td>0.504942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216574</td>\n",
       "      <td>0.225429</td>\n",
       "      <td>0.236775</td>\n",
       "      <td>0.209145</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.568187</td>\n",
       "      <td>0.518523</td>\n",
       "      <td>0.547691</td>\n",
       "      <td>0.493838</td>\n",
       "      <td>0.617624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_worst</th>\n",
       "      <td>0.413463</td>\n",
       "      <td>0.277830</td>\n",
       "      <td>0.455774</td>\n",
       "      <td>0.390410</td>\n",
       "      <td>0.472468</td>\n",
       "      <td>0.865809</td>\n",
       "      <td>0.754968</td>\n",
       "      <td>0.667454</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>0.458798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475820</td>\n",
       "      <td>0.360832</td>\n",
       "      <td>0.529408</td>\n",
       "      <td>0.438296</td>\n",
       "      <td>0.568187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892261</td>\n",
       "      <td>0.801080</td>\n",
       "      <td>0.614441</td>\n",
       "      <td>0.810455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_worst</th>\n",
       "      <td>0.526911</td>\n",
       "      <td>0.301025</td>\n",
       "      <td>0.563879</td>\n",
       "      <td>0.512606</td>\n",
       "      <td>0.434926</td>\n",
       "      <td>0.816275</td>\n",
       "      <td>0.884103</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>0.433721</td>\n",
       "      <td>0.346234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573975</td>\n",
       "      <td>0.368366</td>\n",
       "      <td>0.618344</td>\n",
       "      <td>0.543331</td>\n",
       "      <td>0.518523</td>\n",
       "      <td>0.892261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.855434</td>\n",
       "      <td>0.532520</td>\n",
       "      <td>0.686511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>0.744214</td>\n",
       "      <td>0.295316</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.722017</td>\n",
       "      <td>0.503053</td>\n",
       "      <td>0.815573</td>\n",
       "      <td>0.861323</td>\n",
       "      <td>0.910155</td>\n",
       "      <td>0.430297</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787424</td>\n",
       "      <td>0.359755</td>\n",
       "      <td>0.816322</td>\n",
       "      <td>0.747419</td>\n",
       "      <td>0.547691</td>\n",
       "      <td>0.801080</td>\n",
       "      <td>0.855434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502528</td>\n",
       "      <td>0.511114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_worst</th>\n",
       "      <td>0.163953</td>\n",
       "      <td>0.105008</td>\n",
       "      <td>0.189115</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.394309</td>\n",
       "      <td>0.510223</td>\n",
       "      <td>0.409464</td>\n",
       "      <td>0.375744</td>\n",
       "      <td>0.699826</td>\n",
       "      <td>0.334019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243529</td>\n",
       "      <td>0.233027</td>\n",
       "      <td>0.269493</td>\n",
       "      <td>0.209146</td>\n",
       "      <td>0.493838</td>\n",
       "      <td>0.614441</td>\n",
       "      <td>0.532520</td>\n",
       "      <td>0.502528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.537848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>0.051019</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.499316</td>\n",
       "      <td>0.687382</td>\n",
       "      <td>0.514930</td>\n",
       "      <td>0.368661</td>\n",
       "      <td>0.438413</td>\n",
       "      <td>0.767297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093492</td>\n",
       "      <td>0.219122</td>\n",
       "      <td>0.138957</td>\n",
       "      <td>0.079647</td>\n",
       "      <td>0.617624</td>\n",
       "      <td>0.810455</td>\n",
       "      <td>0.686511</td>\n",
       "      <td>0.511114</td>\n",
       "      <td>0.537848</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "radius_mean                 1.000000      0.323782        0.997855   0.987357   \n",
       "texture_mean                0.323782      1.000000        0.329533   0.321086   \n",
       "perimeter_mean              0.997855      0.329533        1.000000   0.986507   \n",
       "area_mean                   0.987357      0.321086        0.986507   1.000000   \n",
       "smoothness_mean             0.170581     -0.023389        0.207278   0.177028   \n",
       "compactness_mean            0.506124      0.236702        0.556936   0.498502   \n",
       "concavity_mean              0.676764      0.302418        0.716136   0.685983   \n",
       "concave points_mean         0.822529      0.293464        0.850977   0.823269   \n",
       "symmetry_mean               0.147741      0.071401        0.183027   0.151293   \n",
       "fractal_dimension_mean     -0.311631     -0.076437       -0.261477  -0.283110   \n",
       "radius_se                   0.679090      0.275869        0.691765   0.732562   \n",
       "texture_se                 -0.097317      0.386358       -0.086761  -0.066280   \n",
       "perimeter_se                0.674172      0.281673        0.693135   0.726628   \n",
       "area_se                     0.735864      0.259845        0.744983   0.800086   \n",
       "smoothness_se              -0.222600      0.006614       -0.202694  -0.166777   \n",
       "compactness_se              0.206000      0.191975        0.250744   0.212583   \n",
       "concavity_se                0.194204      0.143293        0.228082   0.207660   \n",
       "concave points_se           0.376169      0.163851        0.407217   0.372320   \n",
       "symmetry_se                -0.104321      0.009127       -0.081629  -0.072497   \n",
       "fractal_dimension_se       -0.042641      0.054458       -0.005523  -0.019887   \n",
       "radius_worst                0.969539      0.352573        0.969476   0.962746   \n",
       "texture_worst               0.297008      0.912045        0.303038   0.287489   \n",
       "perimeter_worst             0.965137      0.358040        0.970387   0.959120   \n",
       "area_worst                  0.941082      0.343546        0.941550   0.959213   \n",
       "smoothness_worst            0.119616      0.077503        0.150549   0.123523   \n",
       "compactness_worst           0.413463      0.277830        0.455774   0.390410   \n",
       "concavity_worst             0.526911      0.301025        0.563879   0.512606   \n",
       "concave points_worst        0.744214      0.295316        0.771241   0.722017   \n",
       "symmetry_worst              0.163953      0.105008        0.189115   0.143570   \n",
       "fractal_dimension_worst     0.007066      0.119205        0.051019   0.003738   \n",
       "\n",
       "                         smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "radius_mean                     0.170581          0.506124        0.676764   \n",
       "texture_mean                   -0.023389          0.236702        0.302418   \n",
       "perimeter_mean                  0.207278          0.556936        0.716136   \n",
       "area_mean                       0.177028          0.498502        0.685983   \n",
       "smoothness_mean                 1.000000          0.659123        0.521984   \n",
       "compactness_mean                0.659123          1.000000        0.883121   \n",
       "concavity_mean                  0.521984          0.883121        1.000000   \n",
       "concave points_mean             0.553695          0.831135        0.921391   \n",
       "symmetry_mean                   0.557775          0.602641        0.500667   \n",
       "fractal_dimension_mean          0.584792          0.565369        0.336783   \n",
       "radius_se                       0.301467          0.497473        0.631925   \n",
       "texture_se                      0.068406          0.046205        0.076218   \n",
       "perimeter_se                    0.296092          0.548905        0.660391   \n",
       "area_se                         0.246552          0.455653        0.617427   \n",
       "smoothness_se                   0.332375          0.135299        0.098564   \n",
       "compactness_se                  0.318943          0.738722        0.670279   \n",
       "concavity_se                    0.248396          0.570517        0.691270   \n",
       "concave points_se               0.380676          0.642262        0.683260   \n",
       "symmetry_se                     0.200774          0.229977        0.178009   \n",
       "fractal_dimension_se            0.283607          0.507318        0.449301   \n",
       "radius_worst                    0.213120          0.535315        0.688236   \n",
       "texture_worst                   0.036072          0.248133        0.299879   \n",
       "perimeter_worst                 0.238853          0.590210        0.729565   \n",
       "area_worst                      0.206718          0.509604        0.675987   \n",
       "smoothness_worst                0.805324          0.565541        0.448822   \n",
       "compactness_worst               0.472468          0.865809        0.754968   \n",
       "concavity_worst                 0.434926          0.816275        0.884103   \n",
       "concave points_worst            0.503053          0.815573        0.861323   \n",
       "symmetry_worst                  0.394309          0.510223        0.409464   \n",
       "fractal_dimension_worst         0.499316          0.687382        0.514930   \n",
       "\n",
       "                         concave points_mean  symmetry_mean  \\\n",
       "radius_mean                         0.822529       0.147741   \n",
       "texture_mean                        0.293464       0.071401   \n",
       "perimeter_mean                      0.850977       0.183027   \n",
       "area_mean                           0.823269       0.151293   \n",
       "smoothness_mean                     0.553695       0.557775   \n",
       "compactness_mean                    0.831135       0.602641   \n",
       "concavity_mean                      0.921391       0.500667   \n",
       "concave points_mean                 1.000000       0.462497   \n",
       "symmetry_mean                       0.462497       1.000000   \n",
       "fractal_dimension_mean              0.166917       0.479921   \n",
       "radius_se                           0.698050       0.303379   \n",
       "texture_se                          0.021480       0.128053   \n",
       "perimeter_se                        0.710650       0.313893   \n",
       "area_se                             0.690299       0.223970   \n",
       "smoothness_se                       0.027653       0.187321   \n",
       "compactness_se                      0.490424       0.421659   \n",
       "concavity_se                        0.439167       0.342627   \n",
       "concave points_se                   0.615634       0.393298   \n",
       "symmetry_se                         0.095351       0.449137   \n",
       "fractal_dimension_se                0.257584       0.331786   \n",
       "radius_worst                        0.830318       0.185728   \n",
       "texture_worst                       0.292752       0.090651   \n",
       "perimeter_worst                     0.855923       0.219169   \n",
       "area_worst                          0.809630       0.177193   \n",
       "smoothness_worst                    0.452753       0.426675   \n",
       "compactness_worst                   0.667454       0.473200   \n",
       "concavity_worst                     0.752399       0.433721   \n",
       "concave points_worst                0.910155       0.430297   \n",
       "symmetry_worst                      0.375744       0.699826   \n",
       "fractal_dimension_worst             0.368661       0.438413   \n",
       "\n",
       "                         fractal_dimension_mean  ...  radius_worst  \\\n",
       "radius_mean                           -0.311631  ...      0.969539   \n",
       "texture_mean                          -0.076437  ...      0.352573   \n",
       "perimeter_mean                        -0.261477  ...      0.969476   \n",
       "area_mean                             -0.283110  ...      0.962746   \n",
       "smoothness_mean                        0.584792  ...      0.213120   \n",
       "compactness_mean                       0.565369  ...      0.535315   \n",
       "concavity_mean                         0.336783  ...      0.688236   \n",
       "concave points_mean                    0.166917  ...      0.830318   \n",
       "symmetry_mean                          0.479921  ...      0.185728   \n",
       "fractal_dimension_mean                 1.000000  ...     -0.253691   \n",
       "radius_se                              0.000111  ...      0.715065   \n",
       "texture_se                             0.164174  ...     -0.111690   \n",
       "perimeter_se                           0.039830  ...      0.697201   \n",
       "area_se                               -0.090170  ...      0.757373   \n",
       "smoothness_se                          0.401964  ...     -0.230691   \n",
       "compactness_se                         0.559837  ...      0.204607   \n",
       "concavity_se                           0.446630  ...      0.186904   \n",
       "concave points_se                      0.341198  ...      0.358127   \n",
       "symmetry_se                            0.345007  ...     -0.128121   \n",
       "fractal_dimension_se                   0.688132  ...     -0.037488   \n",
       "radius_worst                          -0.253691  ...      1.000000   \n",
       "texture_worst                         -0.051269  ...      0.359921   \n",
       "perimeter_worst                       -0.205151  ...      0.993708   \n",
       "area_worst                            -0.231854  ...      0.984015   \n",
       "smoothness_worst                       0.504942  ...      0.216574   \n",
       "compactness_worst                      0.458798  ...      0.475820   \n",
       "concavity_worst                        0.346234  ...      0.573975   \n",
       "concave points_worst                   0.175325  ...      0.787424   \n",
       "symmetry_worst                         0.334019  ...      0.243529   \n",
       "fractal_dimension_worst                0.767297  ...      0.093492   \n",
       "\n",
       "                         texture_worst  perimeter_worst  area_worst  \\\n",
       "radius_mean                   0.297008         0.965137    0.941082   \n",
       "texture_mean                  0.912045         0.358040    0.343546   \n",
       "perimeter_mean                0.303038         0.970387    0.941550   \n",
       "area_mean                     0.287489         0.959120    0.959213   \n",
       "smoothness_mean               0.036072         0.238853    0.206718   \n",
       "compactness_mean              0.248133         0.590210    0.509604   \n",
       "concavity_mean                0.299879         0.729565    0.675987   \n",
       "concave points_mean           0.292752         0.855923    0.809630   \n",
       "symmetry_mean                 0.090651         0.219169    0.177193   \n",
       "fractal_dimension_mean       -0.051269        -0.205151   -0.231854   \n",
       "radius_se                     0.194799         0.719684    0.751548   \n",
       "texture_se                    0.409003        -0.102242   -0.083195   \n",
       "perimeter_se                  0.200371         0.721031    0.730713   \n",
       "area_se                       0.196497         0.761213    0.811408   \n",
       "smoothness_se                -0.074743        -0.217304   -0.182195   \n",
       "compactness_se                0.143003         0.260516    0.199371   \n",
       "concavity_se                  0.100241         0.226680    0.188353   \n",
       "concave points_se             0.086741         0.394999    0.342271   \n",
       "symmetry_se                  -0.077473        -0.103753   -0.110343   \n",
       "fractal_dimension_se         -0.003195        -0.001000   -0.022736   \n",
       "radius_worst                  0.359921         0.993708    0.984015   \n",
       "texture_worst                 1.000000         0.365098    0.345842   \n",
       "perimeter_worst               0.365098         1.000000    0.977578   \n",
       "area_worst                    0.345842         0.977578    1.000000   \n",
       "smoothness_worst              0.225429         0.236775    0.209145   \n",
       "compactness_worst             0.360832         0.529408    0.438296   \n",
       "concavity_worst               0.368366         0.618344    0.543331   \n",
       "concave points_worst          0.359755         0.816322    0.747419   \n",
       "symmetry_worst                0.233027         0.269493    0.209146   \n",
       "fractal_dimension_worst       0.219122         0.138957    0.079647   \n",
       "\n",
       "                         smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "radius_mean                      0.119616           0.413463         0.526911   \n",
       "texture_mean                     0.077503           0.277830         0.301025   \n",
       "perimeter_mean                   0.150549           0.455774         0.563879   \n",
       "area_mean                        0.123523           0.390410         0.512606   \n",
       "smoothness_mean                  0.805324           0.472468         0.434926   \n",
       "compactness_mean                 0.565541           0.865809         0.816275   \n",
       "concavity_mean                   0.448822           0.754968         0.884103   \n",
       "concave points_mean              0.452753           0.667454         0.752399   \n",
       "symmetry_mean                    0.426675           0.473200         0.433721   \n",
       "fractal_dimension_mean           0.504942           0.458798         0.346234   \n",
       "radius_se                        0.141919           0.287103         0.380585   \n",
       "texture_se                      -0.073658          -0.092439        -0.068956   \n",
       "perimeter_se                     0.130054           0.341919         0.418899   \n",
       "area_se                          0.125389           0.283257         0.385100   \n",
       "smoothness_se                    0.314457          -0.055558        -0.058298   \n",
       "compactness_se                   0.227394           0.678780         0.639147   \n",
       "concavity_se                     0.168481           0.484858         0.662564   \n",
       "concave points_se                0.215351           0.452888         0.549592   \n",
       "symmetry_se                     -0.012662           0.060255         0.037119   \n",
       "fractal_dimension_se             0.170568           0.390159         0.379975   \n",
       "radius_worst                     0.216574           0.475820         0.573975   \n",
       "texture_worst                    0.225429           0.360832         0.368366   \n",
       "perimeter_worst                  0.236775           0.529408         0.618344   \n",
       "area_worst                       0.209145           0.438296         0.543331   \n",
       "smoothness_worst                 1.000000           0.568187         0.518523   \n",
       "compactness_worst                0.568187           1.000000         0.892261   \n",
       "concavity_worst                  0.518523           0.892261         1.000000   \n",
       "concave points_worst             0.547691           0.801080         0.855434   \n",
       "symmetry_worst                   0.493838           0.614441         0.532520   \n",
       "fractal_dimension_worst          0.617624           0.810455         0.686511   \n",
       "\n",
       "                         concave points_worst  symmetry_worst  \\\n",
       "radius_mean                          0.744214        0.163953   \n",
       "texture_mean                         0.295316        0.105008   \n",
       "perimeter_mean                       0.771241        0.189115   \n",
       "area_mean                            0.722017        0.143570   \n",
       "smoothness_mean                      0.503053        0.394309   \n",
       "compactness_mean                     0.815573        0.510223   \n",
       "concavity_mean                       0.861323        0.409464   \n",
       "concave points_mean                  0.910155        0.375744   \n",
       "symmetry_mean                        0.430297        0.699826   \n",
       "fractal_dimension_mean               0.175325        0.334019   \n",
       "radius_se                            0.531062        0.094543   \n",
       "texture_se                          -0.119638       -0.128215   \n",
       "perimeter_se                         0.554897        0.109930   \n",
       "area_se                              0.538166        0.074126   \n",
       "smoothness_se                       -0.102007       -0.107342   \n",
       "compactness_se                       0.483208        0.277878   \n",
       "concavity_se                         0.440472        0.197788   \n",
       "concave points_se                    0.602450        0.143116   \n",
       "symmetry_se                         -0.030413        0.389402   \n",
       "fractal_dimension_se                 0.215204        0.111094   \n",
       "radius_worst                         0.787424        0.243529   \n",
       "texture_worst                        0.359755        0.233027   \n",
       "perimeter_worst                      0.816322        0.269493   \n",
       "area_worst                           0.747419        0.209146   \n",
       "smoothness_worst                     0.547691        0.493838   \n",
       "compactness_worst                    0.801080        0.614441   \n",
       "concavity_worst                      0.855434        0.532520   \n",
       "concave points_worst                 1.000000        0.502528   \n",
       "symmetry_worst                       0.502528        1.000000   \n",
       "fractal_dimension_worst              0.511114        0.537848   \n",
       "\n",
       "                         fractal_dimension_worst  \n",
       "radius_mean                             0.007066  \n",
       "texture_mean                            0.119205  \n",
       "perimeter_mean                          0.051019  \n",
       "area_mean                               0.003738  \n",
       "smoothness_mean                         0.499316  \n",
       "compactness_mean                        0.687382  \n",
       "concavity_mean                          0.514930  \n",
       "concave points_mean                     0.368661  \n",
       "symmetry_mean                           0.438413  \n",
       "fractal_dimension_mean                  0.767297  \n",
       "radius_se                               0.049559  \n",
       "texture_se                             -0.045655  \n",
       "perimeter_se                            0.085433  \n",
       "area_se                                 0.017539  \n",
       "smoothness_se                           0.101480  \n",
       "compactness_se                          0.590973  \n",
       "concavity_se                            0.439329  \n",
       "concave points_se                       0.310655  \n",
       "symmetry_se                             0.078079  \n",
       "fractal_dimension_se                    0.591328  \n",
       "radius_worst                            0.093492  \n",
       "texture_worst                           0.219122  \n",
       "perimeter_worst                         0.138957  \n",
       "area_worst                              0.079647  \n",
       "smoothness_worst                        0.617624  \n",
       "compactness_worst                       0.810455  \n",
       "concavity_worst                         0.686511  \n",
       "concave points_worst                    0.511114  \n",
       "symmetry_worst                          0.537848  \n",
       "fractal_dimension_worst                 1.000000  \n",
       "\n",
       "[30 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Omwx5vVbYKeo"
   },
   "source": [
    "### 3. Logistic Regression Model\n",
    "\n",
    "#### 3.1 Use Logistic Regression\n",
    "\n",
    "Use Logistic Regression and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']]\n",
    "y = df.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'M',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standard scale X_train amd x_test and \n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# create Model and fit scaled predictors\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(scaled_X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(scaled_X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      0.99      0.98        72\n",
      "           M       0.98      0.95      0.96        42\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71  1]\n",
      " [ 2 40]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mogg_w8vYKep"
   },
   "source": [
    "### 4. Support Vector Machine\n",
    "\n",
    "#### 4.1 Use Support Vector Machine\n",
    "\n",
    "Use Support Vector Machine and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']]\n",
    "y = df.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'M',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standard scale X_train amd x_test and \n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "#Import svm model\n",
    "\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear', random_state = 45, probability = True,  ) # rbf Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(scaled_X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(scaled_X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9824561403508771"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      1.00      0.99        72\n",
      "           M       1.00      0.95      0.98        42\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72  0]\n",
      " [ 2 40]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdzQkTb7YKeq"
   },
   "source": [
    "### 5. Naive Bayes\n",
    "#### 5.1 Use Naive Bayes\n",
    "\n",
    "Use Naive Bayes and examine accuracy score, confusion matrix, classification report for that model.\n",
    "\n",
    "- Define Target, Predictors\n",
    "- Train-Test Split\n",
    "- Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']]\n",
    "y = df.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard scale X_train amd x_test and \n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'M', 'M', 'M', 'M', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'M',\n",
       "       'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M'], dtype='<U1')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets \n",
    "model.fit(scaled_X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298245614035088"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.93      0.96      0.95        72\n",
      "           M       0.93      0.88      0.90        42\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69  3]\n",
      " [ 5 37]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoGxthaeYKer"
   },
   "source": [
    "### 6 Gridsearch optimal parameters for all three models.\n",
    "\n",
    "Is there any difference between accuracy score of Logistic Regression and SVM? Use grid serach to find optimal parameter for both these models.\n",
    "\n",
    "> Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. Typical examples include C, kernel and gamma for Support Vector Classifier, alpha for Lasso, etc.\n",
    "\n",
    "> It is possible and recommended to search the hyper-parameter space for the best cross validation score.\n",
    "\n",
    "> https://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "\n",
    "**Note:** It'll take time to execute this. After running the cell, wait for result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UeqrbsyNYKes"
   },
   "source": [
    "#### 6.1 Find Best Estimator For Logistic Regression \n",
    "\n",
    "Find out how these parameters effect model. Find out the best estimator, score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [c for c in df.columns if c != 'diagnosis']\n",
    "X = df[feature_columns]\n",
    "y = df.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:40:29.397881Z",
     "start_time": "2019-05-09T05:40:29.392602Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UkQ9RBQZYKet"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l1; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ....................................C=1, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l1; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ...................................C=10, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l1; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n",
      "[CV] END ..................................C=100, penalty=l2; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.94729079        nan 0.93496351        nan 0.94379755]\n",
      "  warnings.warn(\n",
      "C:\\Users\\dmuwa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 10, 100], 'penalty': ['l1', 'l2']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_params = {\n",
    "    'penalty': ['l1','l2'],\n",
    "    'C': [1, 10, 100]\n",
    "}\n",
    "\n",
    "lr_gs = GridSearchCV(LogisticRegression(), lr_params, cv = 5, verbose = 2)\n",
    "lr_gs.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l2'}\n",
      "0.947290793355069\n"
     ]
    }
   ],
   "source": [
    "best_svc = lr_gs.best_estimator_\n",
    "print(lr_gs.best_params_)\n",
    "print(lr_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:23:14.036840Z",
     "start_time": "2019-05-09T05:23:14.032847Z"
    },
    "colab_type": "text",
    "id": "ioLgY3bxYKev"
   },
   "source": [
    "#### 6.2 Find Best Estimator For SVM\n",
    "\n",
    "Find out how these parameters effect model. Find out the best estimator, score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:40:31.617090Z",
     "start_time": "2019-05-09T05:40:31.612996Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "vgi61VpWYKew"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   3.7s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   3.6s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   3.8s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   3.4s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   3.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   4.7s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   5.9s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   6.9s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   4.0s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   3.1s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=  20.7s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=  17.8s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=  16.8s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=  21.5s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=  18.9s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=  19.2s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=  17.8s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=  23.8s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=   8.3s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=  19.2s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=  34.1s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=  41.2s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=  33.3s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=  14.9s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=  37.8s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=  19.4s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=  43.9s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=  40.2s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=  33.4s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=  34.6s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(probability=True),\n",
       "             param_grid={'C': [1, 10, 100], 'gamma': [0.001, 0.0001],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_params = {\n",
    "    'C': [1, 10, 100],\n",
    "    'gamma': [0.001, 0.0001],\n",
    "    'kernel': ['linear','rbf']\n",
    "}\n",
    "\n",
    "svc_gs = GridSearchCV(svm.SVC(probability = True), svc_params, cv = 5, verbose = 2)\n",
    "svc_gs.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.9543393882937432\n"
     ]
    }
   ],
   "source": [
    "best_svc = svc_gs.best_estimator_\n",
    "print(svc_gs.best_params_)\n",
    "print(svc_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:23:59.157703Z",
     "start_time": "2019-05-09T05:23:59.153713Z"
    },
    "colab_type": "text",
    "id": "HrS04DfuYKez"
   },
   "source": [
    "#### 6.3 Plot the ROC curve for the SVM, Logistic Regressions and Naive Bayes on the same plot\n",
    "\n",
    "Find out which model performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 611,
       "width": 689
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat_pp_lin = lr_gs.predict_proba(X_test)\n",
    "yhat_pp = svc_gs.predict_proba(X_test)\n",
    "yhat_pp_nb = model.predict_proba(scaled_X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, yhat_pp_lin[:,1], pos_label='M')\n",
    "fpr_svc, tpr_svc, _ = roc_curve(y_test, yhat_pp[:,1], pos_label='M')\n",
    "fpr_nb, tpr_nb, _ = roc_curve(y_test, yhat_pp_nb[:,1], pos_label='M')\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve Logistic (area = %0.2f)' % auc(fpr, tpr), linewidth=4)\n",
    "plt.plot(fpr_svc, tpr_svc, label='ROC curve SVC (area = %0.2f)' % auc(fpr_svc, tpr_svc), linewidth=4, color='darkred')\n",
    "plt.plot(fpr_nb, tpr_nb, label='ROC curve NB (area = %0.2f)' % auc(fpr_nb, tpr_nb), linewidth=4, color='darkblue')\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Receiver operating characteristic: M', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WrSrz3AAYKe3"
   },
   "source": [
    "### 7. [BONUS] Learning Curve\n",
    "\n",
    "A learning curve shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much we benefit from adding more training data and whether the estimator suffers more from a variance error or a bias error. If both the validation score and the training score converge to a value that is too low with increasing size of the training set, we will not benefit much from more training data.\n",
    "\n",
    "Plot \"learning curves\" for the best models of each. This is a great way see how training/testing size affects the scores. Look at the documentation for how to use this function in sklearn.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/learning_curve.html#learning-curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T05:22:19.657638Z",
     "start_time": "2019-05-09T05:22:19.653657Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3Zleg5E-YKe4"
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html#sphx-glr-auto-examples-model-selection-plot-learning-curve-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE8SgkpSYKe7"
   },
   "source": [
    "**References**\n",
    "\n",
    "[Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data/downloads/breast-cancer-wisconsin-data.zip/2)\n",
    "\n",
    "[Validation curves: plotting scores to evaluate models](https://scikit-learn.org/stable/modules/learning_curve.html#learning-curves)\n",
    "\n",
    "[In-Depth: Support Vector Machines](https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html)\n",
    "\n",
    "[Understanding Support Vector Machine algorithm from examples (along with code)](https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/)\n",
    "\n",
    "[Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2021 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IOD_Lab_5_3_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
